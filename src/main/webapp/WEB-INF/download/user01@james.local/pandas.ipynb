{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TUBkfoNGpRhI"
   },
   "source": [
    "#**Python Pandas** (데이터 분석을 위한 강력한 데이터 조작 라이브러리)\n",
    "\n",
    "##**목차**\n",
    "\n",
    "1. Pandas 소개\n",
    "\n",
    "  1.1 Pandas란 무엇인가?\n",
    "\n",
    "  1.2 Pandas의 역사와 발전\n",
    "\n",
    "  1.3 Pandas를 활용한 간단한 예제\n",
    "\n",
    "  1.4 학습 목표 및 기대 효과\n",
    "\n",
    "2. 기본 자료구조: Series와 DataFrame\n",
    "\n",
    "  2.1 Series\n",
    "\n",
    "  2.2 DataFrame\n",
    "\n",
    "  2.3 Series와 DataFrame의 차이점 및 활용\n",
    "\n",
    "  2.4 학습 목표\n",
    "\n",
    "3. 데이터 입출력 (I/O)\n",
    "\n",
    "  3.1 CSV 파일 입출력\n",
    "\n",
    "  3.2 Excel 파일 입출력\n",
    "\n",
    "  3.3 JSON 파일 입출력\n",
    "\n",
    "  3.4 SQL 데이터베이스 입출력\n",
    "\n",
    "  3.5 기타 입출력 기능\n",
    "\n",
    "  3.6 실습 예제 및 유의사항\n",
    "\n",
    "  3.7 요약\n",
    "\n",
    "4. 데이터 인덱싱, 선택 및 필터링\n",
    "\n",
    "  4.1 기본 인덱싱\n",
    "\n",
    "  4.2 라벨 및 위치 기반 인덱싱: loc, iloc, at, iat\n",
    "\n",
    "  4.3 불리언 인덱싱 및 조건 필터링\n",
    "\n",
    "  4.4 고급 선택 기법 및 주의사항\n",
    "\n",
    "  4.5 요약\n",
    "\n",
    "5. 데이터 전처리 및 정제\n",
    "\n",
    "  5.1 결측치 처리 (Missing Value Handling)\n",
    "\n",
    "  5.2 중복 데이터 처리 (Handling Duplicates)\n",
    "\n",
    "  5.3 데이터 타입 변환 및 문자열 처리\n",
    "\n",
    "  5.4 파생 변수 생성 및 데이터 변환\n",
    "\n",
    "  5.5 데이터 전처리 실습 팁 및 주의사항\n",
    "\n",
    "  5.6 요약\n",
    "\n",
    "6. 데이터 병합, 결합 및 분할\n",
    "\n",
    "  6.1 데이터 병합 (Merging)\n",
    "\n",
    "  6.2 데이터 결합 (Concatenation)\n",
    "\n",
    "  6.3 데이터 분할 (Splitting)\n",
    "\n",
    "  6.4 유의사항 및 활용 팁\n",
    "\n",
    "  6.5 요약\n",
    "\n",
    "7. 시계열 데이터 처리\n",
    "\n",
    "  7.1 시계열 데이터의 이해\n",
    "\n",
    "  7.2 시계열 데이터 생성 및 인덱스 설정\n",
    "\n",
    "  7.3 리샘플링 (Resampling)\n",
    "\n",
    "  7.4 이동 윈도우 (Rolling Window) 연산\n",
    "\n",
    "  7.5 시간대 변환 및 시계열 데이터 정렬\n",
    "\n",
    "  7.6 기타 시계열 관련 기능\n",
    "\n",
    "  7.7 요약\n",
    "\n",
    "8. 데이터 시각화와 보고\n",
    "\n",
    "  8.1 Pandas 내장 시각화 기능\n",
    "\n",
    "  8.2 Matplotlib 연동과 시각화 커스터마이징\n",
    "\n",
    "  8.3 데이터 시각화를 활용한 보고서 작성\n",
    "\n",
    "  8.4 실습 예제 및 팁\n",
    "\n",
    "  8.5 요약\n",
    "\n",
    "9. 실습 문제 및 응용 프로젝트\n",
    "\n",
    "  9.1 실습 문제의 목적 및 구성\n",
    "\n",
    "  9.2 실습 문제 예제\n",
    "\n",
    "  9.3 응용 프로젝트 예제\n",
    "\n",
    "  9.4 프로젝트 진행 시 유의사항\n",
    "\n",
    "  9.5 요약"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pWcfXRe9chqo"
   },
   "source": [
    "#**1. Pandas 소개**\n",
    "\n",
    "##**1.1 Pandas란 무엇인가?**\n",
    "\n",
    "*   **정의 및 역할:**\n",
    "\n",
    "  Pandas는 표 형식의 데이터를 효율적으로 처리하고 분석할 수 있도록 돕는 Python 라이브러리입니다.\n",
    "\n",
    "  *   **주요 자료구조:**\n",
    "\n",
    "      **Series:** 1차원 데이터 구조로, 인덱스와 값으로 구성됩니다.\n",
    "      \n",
    "      **DataFrame:** 행과 열로 구성된 2차원 데이터 구조로, 엑셀 시트와 유사하게 다양한 데이터 타입을 함께 다룰 수 있습니다.\n",
    "      \n",
    "  *   **활용 분야:**\n",
    "\n",
    "      데이터 전처리, 통계 분석, 시계열 분석, 데이터 시각화 등 데이터 과학 및 머신러닝 프로젝트 전반에 사용됩니다.\n",
    "\n",
    "*   **Pandas의 장점:**\n",
    "      \n",
    "  *   **직관적 데이터 조작:** 복잡한 데이터 구조를 간단한 문법으로 다룰 수 있습니다.\n",
    "      \n",
    "  *   **다양한 입출력 기능:** CSV, Excel, SQL, JSON 등 다양한 데이터 포맷을 쉽게 읽고 쓸 수 있습니다.\n",
    "        \n",
    "  *   **풍부한 내장 함수:** 데이터 정제, 변환, 그룹화, 집계 등 데이터 분석에 필요한 다양한 기능을 제공합니다.\n",
    "\n",
    "##**1.2 Pandas의 역사와 발전**\n",
    "\n",
    "*   Pandas는 Wes McKinney가 개발하였으며, 2008년부터 시작되어 현재 데이터 분석 분야에서 표준 라이브러리로 자리잡고 있습니다.\n",
    "\n",
    "*   빠른 속도와 직관적인 문법 덕분에, 연구 및 산업 전반에서 널리 사용되고 있습니다.\n",
    "\n",
    "##**1.3 Pandas를 활용한 간단한 예제**\n",
    "\n",
    "아래 코드는 Pandas의 기본 기능을 확인할 수 있는 간단한 예제입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 865,
     "status": "ok",
     "timestamp": 1740191019139,
     "user": {
      "displayName": "이유태",
      "userId": "01951466277766633919"
     },
     "user_tz": -540
    },
    "id": "nVZ1JU65d3fo",
    "outputId": "2b604ca4-722b-4129-fe31-d047892d6de1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series 예제:\n",
      "a    100\n",
      "b    200\n",
      "c    300\n",
      "dtype: int64\n",
      "\n",
      "DataFrame 예제:\n",
      "        이름  나이  도시\n",
      "0    Alice  25  서울\n",
      "1      Bob  30  부산\n",
      "2  Charlie  35  대구\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 간단한 Series 생성\n",
    "s = pd.Series([100, 200, 300], index=['a', 'b', 'c'])\n",
    "print(\"Series 예제:\")\n",
    "print(s)\n",
    "\n",
    "# DataFrame 생성\n",
    "data = {'이름': ['Alice', 'Bob', 'Charlie'],\n",
    "        '나이': [25, 30, 35],\n",
    "        '도시': ['서울', '부산', '대구']}\n",
    "df = pd.DataFrame(data)\n",
    "print(\"\\nDataFrame 예제:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GCuLWjVmd9GY"
   },
   "source": [
    "*   **Series와 DataFrame:**\n",
    "\n",
    "  위 예제에서는 Pandas의 두 가지 주요 자료구조인 Series와 DataFrame을 생성하고 출력하는 과정을 보여줍니다.\n",
    "\n",
    "*   **출력 확인:**\n",
    "\n",
    "  Pandas 버전을 출력하고, 간단한 데이터 구조를 확인함으로써 설치와 환경 설정이 정상적으로 이루어졌는지 검증할 수 있습니다.\n",
    "\n",
    "##**1.4 학습 목표 및 기대 효과**\n",
    "\n",
    "*   **핵심 개념 이해:**\n",
    "\n",
    "  Pandas의 기본 개념과 자료구조(Series, DataFrame)를 이해하여, 이후 데이터 전처리 및 분석 과정에 원활하게 적용할 수 있습니다.\n",
    "\n",
    "*   **실습을 통한 익숙함:**\n",
    "\n",
    "  간단한 예제 코드를 통해 Pandas의 사용법에 익숙해지고, 데이터 분석에 필요한 기본 기능을 체험합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ANAcuFDxeyfQ"
   },
   "source": [
    "#**2. 기본 자료구조: Series와 DataFrame**\n",
    "Pandas의 핵심은 데이터를 효율적으로 저장하고 다루기 위한 두 가지 주요 자료구조인 Series와 DataFrame입니다. 이 장에서는 각 자료구조의 정의, 생성 방법, 주요 속성과 메서드, 그리고 실습 예제를 통해 사용법을 상세하게 살펴봅니다.\n",
    "\n",
    "##**2.1 Series**\n",
    "\n",
    "###**2.1.1 Series란?**\n",
    "\n",
    "*   **정의:**\n",
    "\n",
    "  Series는 1차원 배열과 유사한 자료구조로, 인덱스와 값으로 구성됩니다.\n",
    "\n",
    "  *   각 요소는 하나의 값이며, 인덱스를 통해 개별 요소에 접근할 수 있습니다.\n",
    "  \n",
    "  *   인덱스는 기본적으로 정수형이지만, 사용자 정의 라벨을 사용할 수도 있습니다.\n",
    "\n",
    "*   **특징:**\n",
    "\n",
    "  *   **인덱스와 값:**\n",
    "  \n",
    "      인덱스는 데이터의 레이블 역할을 하며, 값은 실제 데이터입니다.\n",
    "\n",
    "  *   **동일한 데이터 타입:**\n",
    "  \n",
    "      Series의 모든 요소는 동일한 데이터 타입을 갖습니다(내부적으로 NumPy 배열로 관리).\n",
    "\n",
    "###**2.1.2 Series 생성 및 활용**\n",
    "\n",
    "*   **Series 생성 예제:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1740191440314,
     "user": {
      "displayName": "이유태",
      "userId": "01951466277766633919"
     },
     "user_tz": -540
    },
    "id": "O7YKGC22fgvn",
    "outputId": "9307ebd0-f288-4534-e6c2-ea4d8522eae3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기본 인덱스 Series:\n",
      "0    10\n",
      "1    20\n",
      "2    30\n",
      "3    40\n",
      "dtype: int64\n",
      "\n",
      "사용자 정의 인덱스 Series:\n",
      "a    100\n",
      "b    200\n",
      "c    300\n",
      "d    400\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 기본 인덱스가 자동 할당된 Series 생성\n",
    "s1 = pd.Series([10, 20, 30, 40])\n",
    "print(\"기본 인덱스 Series:\")\n",
    "print(s1)\n",
    "\n",
    "# 사용자 정의 인덱스를 지정한 Series 생성\n",
    "s2 = pd.Series([100, 200, 300, 400], index=['a', 'b', 'c', 'd'])\n",
    "print(\"\\n사용자 정의 인덱스 Series:\")\n",
    "print(s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CkBkNeepfkgX"
   },
   "source": [
    "*   **주요 속성 및 메서드:**\n",
    "\n",
    "  *   `index`: Series의 인덱스를 반환합니다.\n",
    "\n",
    "  *   `values`: Series의 값들을 NumPy 배열로 반환합니다.\n",
    "\n",
    "  *   `head()`, `tail()`: 처음 또는 마지막 몇 개의 데이터를 확인합니다.\n",
    "\n",
    "  *   `describe()`: 요약 통계 정보를 제공합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1740191535611,
     "user": {
      "displayName": "이유태",
      "userId": "01951466277766633919"
     },
     "user_tz": -540
    },
    "id": "4XXEIKHrf393",
    "outputId": "a8823622-4867-45f6-ef83-2883b5b53b67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인덱스: Index(['a', 'b', 'c', 'd'], dtype='object')\n",
      "값: [100 200 300 400]\n",
      "\n",
      "요약 통계:\n",
      "count      4.000000\n",
      "mean     250.000000\n",
      "std      129.099445\n",
      "min      100.000000\n",
      "25%      175.000000\n",
      "50%      250.000000\n",
      "75%      325.000000\n",
      "max      400.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"인덱스:\", s2.index)\n",
    "print(\"값:\", s2.values)\n",
    "print(\"\\n요약 통계:\")\n",
    "print(s2.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yV-UJp05f8p_"
   },
   "source": [
    "##**2.2 DataFrame**\n",
    "\n",
    "###**2.2.1 DataFrame이란?**\n",
    "\n",
    "*   **정의:**\n",
    "\n",
    "  DataFrame은 행과 열로 구성된 2차원 표 형태의 자료구조입니다.\n",
    "\n",
    "  *   각 열은 Series 객체이며, 서로 다른 데이터 타입을 가질 수 있습니다.\n",
    "  \n",
    "  *   행과 열 모두에 인덱스(라벨)를 부여할 수 있어, 데이터의 위치를 명확히 식별할 수 있습니다.\n",
    "\n",
    "*   **특징:**\n",
    "\n",
    "  *   **다양한 데이터 타입:**\n",
    "  \n",
    "      각 열이 서로 다른 데이터 타입(정수, 실수, 문자열 등)을 가질 수 있어, 복잡한 데이터를 효율적으로 저장합니다.\n",
    "\n",
    "  *   **데이터 조작 기능:**\n",
    "  \n",
    "      데이터 필터링, 정렬, 그룹화, 피벗 등 다양한 기능이 내장되어 있습니다.\n",
    "\n",
    "###**2.2.2 DataFrame 생성 및 활용**\n",
    "\n",
    "*   **DataFrame 생성 예제:**\n",
    "\n",
    "  일반적으로 딕셔너리 형태의 데이터를 사용하여 DataFrame을 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1740191638254,
     "user": {
      "displayName": "이유태",
      "userId": "01951466277766633919"
     },
     "user_tz": -540
    },
    "id": "lxkPWMehgQ23",
    "outputId": "5255679f-6443-4af9-9daf-53c36aa112d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 예제:\n",
      "        이름  나이  도시\n",
      "0    Alice  25  서울\n",
      "1      Bob  30  부산\n",
      "2  Charlie  35  대구\n",
      "3    David  40  인천\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    '이름': ['Alice', 'Bob', 'Charlie', 'David'],\n",
    "    '나이': [25, 30, 35, 40],\n",
    "    '도시': ['서울', '부산', '대구', '인천']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(\"DataFrame 예제:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cz452-ctgTXX"
   },
   "source": [
    "*   **주요 속성 및 메서드:**\n",
    "\n",
    "  *   `df.index`: 행 인덱스 정보를 확인합니다.\n",
    "\n",
    "  *   `df.columns`: 열의 이름(라벨)을 반환합니다.\n",
    "\n",
    "  *   `df.dtypes`: 각 열의 데이터 타입을 확인할 수 있습니다.\n",
    "\n",
    "  *   `df.head()`, `df.tail()`: 데이터의 앞부분 또는 뒷부분을 출력합니다.\n",
    "  \n",
    "  *   `df.describe()`: 수치형 열에 대해 기초 통계 정보를 제공합니다.\n",
    "\n",
    "  *   `df.info()`: DataFrame의 전체적인 정보를 요약합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1740191729964,
     "user": {
      "displayName": "이유태",
      "userId": "01951466277766633919"
     },
     "user_tz": -540
    },
    "id": "aaKOoEhMgmfv",
    "outputId": "25b8dfc8-f79b-43c2-ac29-d4273062e076"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "행 인덱스: RangeIndex(start=0, stop=4, step=1)\n",
      "열 이름: Index(['이름', '나이', '도시'], dtype='object')\n",
      "데이터 타입:\n",
      "이름    object\n",
      "나이     int64\n",
      "도시    object\n",
      "dtype: object\n",
      "\n",
      "상위 2개 데이터:\n",
      "      이름  나이  도시\n",
      "0  Alice  25  서울\n",
      "1    Bob  30  부산\n",
      "\n",
      "데이터 요약 통계:\n",
      "              나이\n",
      "count   4.000000\n",
      "mean   32.500000\n",
      "std     6.454972\n",
      "min    25.000000\n",
      "25%    28.750000\n",
      "50%    32.500000\n",
      "75%    36.250000\n",
      "max    40.000000\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n행 인덱스:\", df.index)\n",
    "print(\"열 이름:\", df.columns)\n",
    "print(\"데이터 타입:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(\"\\n상위 2개 데이터:\")\n",
    "print(df.head(2))\n",
    "\n",
    "print(\"\\n데이터 요약 통계:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qOEgnU5Ogpxn"
   },
   "source": [
    "*   **DataFrame 조작 예제:**\n",
    "\n",
    "  특정 열에 접근하거나, 행을 필터링하는 등의 작업을 통해 DataFrame을 자유롭게 다룰 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1740191764742,
     "user": {
      "displayName": "이유태",
      "userId": "01951466277766633919"
     },
     "user_tz": -540
    },
    "id": "BM9fa9tMgv13",
    "outputId": "0b353cf4-d714-4468-a7f9-c215696ff7cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'나이' 열:\n",
      "0    25\n",
      "1    30\n",
      "2    35\n",
      "3    40\n",
      "Name: 나이, dtype: int64\n",
      "\n",
      "나이가 30 이상인 데이터:\n",
      "        이름  나이  도시\n",
      "1      Bob  30  부산\n",
      "2  Charlie  35  대구\n",
      "3    David  40  인천\n"
     ]
    }
   ],
   "source": [
    "# '나이' 열 선택\n",
    "age_series = df['나이']\n",
    "print(\"\\n'나이' 열:\")\n",
    "print(age_series)\n",
    "\n",
    "# 나이가 30 이상인 행 필터링\n",
    "df_filtered = df[df['나이'] >= 30]\n",
    "print(\"\\n나이가 30 이상인 데이터:\")\n",
    "print(df_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qgjzhTU6gza_"
   },
   "source": [
    "##**2.3 Series와 DataFrame의 차이점 및 활용**\n",
    "\n",
    "*   **Series:**\n",
    "\n",
    "  *   1차원 데이터로, 단일 변수의 값을 저장하고, 인덱스를 통한 접근이 용이합니다.\n",
    "  \n",
    "  *   벡터화 연산과 통계 함수 등을 통해 간단한 데이터 분석 및 변환에 활용됩니다.\n",
    "  \n",
    "*   **DataFrame:**\n",
    "\n",
    "  *   2차원 데이터로, 여러 변수(열)를 동시에 관리할 수 있습니다.\n",
    "  \n",
    "  *   데이터 정제, 병합, 그룹화, 피벗 등 복잡한 데이터 분석 작업에 필수적입니다.\n",
    "    \n",
    "*   **실제 활용:**\n",
    "\n",
    "  *   데이터 분석 프로젝트에서는 CSV 파일, 엑셀 파일 등 외부 데이터를 DataFrame으로 불러와 전처리 작업을 수행하고, 이후 필요한 분석 및 시각화를 진행합니다.\n",
    "  \n",
    "  *   Series는 DataFrame의 각 열 또는 특정 변수에 대해 개별적으로 작업할 때 사용됩니다.\n",
    "\n",
    "##**2.4 학습 목표**\n",
    "\n",
    "*   **기본 개념 습득:**\n",
    "\n",
    "  Series와 DataFrame의 정의와 차이점을 명확히 이해하여, Pandas의 핵심 자료구조를 익힙니다.\n",
    "\n",
    "*   **자료구조 생성 및 조작:**\n",
    "\n",
    "  다양한 방법으로 Series와 DataFrame을 생성하고, 인덱싱, 필터링, 통계 요약 등의 기초 작업을 수행할 수 있도록 합니다.\n",
    "  \n",
    "*   **실습을 통한 응용:**\n",
    "\n",
    "  실제 데이터를 다루는 과정에서 Pandas의 자료구조를 활용하여 데이터 전처리, 분석, 시각화에 응용할 수 있는 기초를 마련합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eLbxyUujhck3"
   },
   "source": [
    "#**3. 데이터 입출력 (I/O)**\n",
    "Pandas는 다양한 파일 형식 및 데이터 소스로부터 데이터를 읽어오고 저장하는 기능을 제공합니다. 이 장에서는 CSV, Excel, JSON, SQL 등 여러 형식의 데이터를 Pandas DataFrame으로 불러오고, 다시 저장하는 방법과 각 함수의 주요 옵션에 대해 살펴봅니다.\n",
    "\n",
    "##**3.1 CSV 파일 입출력**\n",
    "\n",
    "*   **CSV 파일 읽기:**\n",
    "\n",
    "  `read_csv()` 함수는 CSV(Comma-Separated Values) 파일을 DataFrame으로 읽어옵니다.\n",
    "\n",
    "  *   **주요 옵션:**\n",
    "\n",
    "      `sep`: 구분자를 지정합니다(기본값은 콤마(',')).\n",
    "      \n",
    "      `header`: 헤더 행의 위치 지정 (예: header=0).\n",
    "      \n",
    "      `index_col`: 특정 열을 인덱스로 사용합니다.\n",
    "      \n",
    "      `encoding`: 파일 인코딩을 지정합니다(예: 'utf-8', 'euc-kr')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P8UnhNxLh8G3"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 기본 CSV 파일 읽기\n",
    "df_csv = pd.read_csv('data.csv')\n",
    "print(\"CSV 파일 읽기 결과:\")\n",
    "print(df_csv.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ApmVekDEiBJf"
   },
   "source": [
    "*   **CSV 파일 저장하기:**\n",
    "\n",
    "  DataFrame을 CSV 파일로 저장할 때는 `to_csv()` 함수를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "veLSTptyioX3"
   },
   "outputs": [],
   "source": [
    "# 인덱스를 포함하지 않고 CSV 파일로 저장\n",
    "df_csv.to_csv('output.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r696u1j-ip_u"
   },
   "source": [
    "##**3.2 Excel 파일 입출력**\n",
    "\n",
    "*   **Excel 파일 읽기:**\n",
    "\n",
    "  `read_excel()` 함수는 Excel 파일(.xlsx, .xls 등)을 DataFrame으로 읽어옵니다.\n",
    "\n",
    "  *   **주요 옵션:**\n",
    "\n",
    "      `sheet_nam`e: 읽을 시트의 이름이나 번호를 지정합니다.\n",
    "      \n",
    "      `header`, `index_col`: CSV 파일과 유사한 옵션을 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QngI2HW0jDoP"
   },
   "outputs": [],
   "source": [
    "# Excel 파일에서 첫 번째 시트를 읽어오기\n",
    "df_excel = pd.read_excel('data.xlsx', sheet_name=0)\n",
    "print(\"Excel 파일 읽기 결과:\")\n",
    "print(df_excel.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x42QFBemjFgW"
   },
   "source": [
    "*   **Excel 파일 저장하기:**\n",
    "\n",
    "  DataFrame을 Excel 파일로 저장할 때는 `to_excel()` 함수를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bzUrKF6fjMQn"
   },
   "outputs": [],
   "source": [
    "# 인덱스 없이 Excel 파일로 저장\n",
    "df_excel.to_excel('output.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QeUzhJsIjPdu"
   },
   "source": [
    "##**3.3 JSON 파일 입출력**\n",
    "\n",
    "*   **JSON 파일 읽기:**\n",
    "\n",
    "  `read_json()` 함수는 JSON 형식의 데이터를 DataFrame으로 변환합니다.\n",
    "\n",
    "  JSON 데이터의 구조에 따라 orient 옵션을 조정할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zm61C2KIjhqf"
   },
   "outputs": [],
   "source": [
    "# JSON 파일 읽기\n",
    "df_json = pd.read_json('data.json')\n",
    "print(\"JSON 파일 읽기 결과:\")\n",
    "print(df_json.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2bzHmfDZjjJ-"
   },
   "source": [
    "*   **JSON 파일 저장하기:**\n",
    "\n",
    "  DataFrame을 JSON 파일로 저장할 때는 to_json() 함수를 사용합니다.\n",
    "\n",
    "  **force_ascii=False** 옵션은 한글 등 비영어권 문자가 깨지지 않도록 도와줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5nD5dVHujynH"
   },
   "outputs": [],
   "source": [
    "# JSON 파일로 저장 (orient 옵션: records)\n",
    "df_json.to_json('output.json', orient='records', force_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pjoos-WWj272"
   },
   "source": [
    "##**3.4 SQL 데이터베이스 입출력**\n",
    "\n",
    "*   **데이터베이스 연결 및 읽기:**\n",
    "\n",
    "  Pandas는 SQLAlchemy 라이브러리와 연동하여 SQL 데이터베이스에서 데이터를 읽어올 수 있습니다.\n",
    "\n",
    "  MySQL, PostgreSQL, Oracle 등 다른 데이터베이스도 SQLAlchemy 드라이버를 이용하여 연결할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bJOC3bIhj-qe"
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "# SQLite 데이터베이스 엔진 생성 (예시)\n",
    "engine = create_engine('sqlite:///sample.db')\n",
    "\n",
    "# SQL 쿼리를 실행하여 DataFrame으로 읽기\n",
    "df_sql = pd.read_sql('SELECT * FROM table_name', engine)\n",
    "print(\"SQL 데이터 읽기 결과:\")\n",
    "print(df_sql.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wl6KH_2FkE0u"
   },
   "source": [
    "*   **SQL 데이터베이스에 저장하기:**\n",
    "\n",
    "  DataFrame을 데이터베이스의 테이블로 저장할 때는 to_sql() 함수를 사용합니다.\n",
    "\n",
    "  *   **if_exists 옵션:**\n",
    "\n",
    "      `fail`: 테이블이 존재하면 아무 작업도 하지 않습니다.\n",
    "      \n",
    "      `replace`: 기존 테이블을 삭제하고 새로 생성합니다.\n",
    "      \n",
    "      `append`: 기존 테이블에 데이터를 추가합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SwVXoT4TkeDm"
   },
   "outputs": [],
   "source": [
    "# DataFrame을 테이블 'new_table'로 저장 (존재하면 대체)\n",
    "df_sql.to_sql('new_table', engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yoCh5nSBkfqu"
   },
   "source": [
    "##**3.5 기타 입출력 기능**\n",
    "\n",
    "*   **HTML 테이블 읽기:**\n",
    "\n",
    "  `read_html()` 함수는 웹페이지 내의 테이블을 DataFrame 목록으로 읽어옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TYf11U0Iko5e"
   },
   "outputs": [],
   "source": [
    "# 웹페이지 URL에 있는 테이블 읽기\n",
    "dfs = pd.read_html('https://example.com/table_page')\n",
    "# 여러 개의 테이블 중 첫 번째 테이블 선택\n",
    "df_html = dfs[0]\n",
    "print(\"HTML 테이블 읽기 결과:\")\n",
    "print(df_html.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2_4mDbBskr92"
   },
   "source": [
    "*   **HDF5 파일 입출력:**\n",
    "\n",
    "  `read_hdf()`와 `to_hdf()` 함수는 대용량 데이터를 효율적으로 저장하는 HDF5 형식을 지원합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KNP7fkZLky7O"
   },
   "outputs": [],
   "source": [
    "# HDF5 파일로 저장\n",
    "df_csv.to_hdf('data.h5', key='df', mode='w')\n",
    "# HDF5 파일 읽기\n",
    "df_hdf = pd.read_hdf('data.h5', key='df')\n",
    "print(\"HDF5 파일 읽기 결과:\")\n",
    "print(df_hdf.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v09gR_6ok1AP"
   },
   "source": [
    "##**3.6 실습 예제 및 유의사항**\n",
    "\n",
    "*   **실습 예제:**\n",
    "\n",
    "  주어진 CSV 파일에서 데이터를 읽어와 결측치를 확인 및 처리한 후, 통계 요약을 출력해보세요.\n",
    "  \n",
    "  Excel 파일에서 특정 시트의 데이터를 읽어와 특정 열만 추출하고, 그 결과를 새로운 CSV 파일로 저장해보세요.\n",
    "  \n",
    "  SQL 데이터베이스에 연결하여, 특정 테이블의 데이터를 DataFrame으로 불러온 후, 그룹별 집계 결과를 출력해보세요.\n",
    "\n",
    "*   **유의사항:**\n",
    "\n",
    "  파일 경로, 인코딩, 구분자 등의 옵션을 적절히 설정해야 데이터가 올바르게 읽히거나 저장됩니다.\n",
    "  \n",
    "  외부 데이터 소스를 사용할 경우, 데이터의 구조나 포맷에 맞게 적절한 파라미터를 지정하는 것이 중요합니다.\n",
    "  \n",
    "  데이터베이스 입출력 시, 보안과 연결 설정에 주의해야 하며, SQLAlchemy 드라이버 설치가 필요할 수 있습니다.\n",
    "\n",
    "##**3.7 요약**\n",
    "\n",
    "*   Pandas는 CSV, Excel, JSON, SQL, HTML, HDF5 등 다양한 형식의 데이터를 손쉽게 읽고 쓸 수 있는 기능을 제공합니다.\n",
    "\n",
    "*   각 입출력 함수는 다양한 옵션을 통해 파일 형식에 맞는 데이터 파싱 및 저장이 가능하도록 지원합니다.\n",
    "\n",
    "*   실제 데이터 분석 프로젝트에서는 외부 데이터를 불러와 전처리하고, 결과를 다양한 형식으로 저장하여 공유할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bhefOv4_lZt2"
   },
   "source": [
    "#**4. 데이터 인덱싱, 선택 및 필터링**\n",
    "Pandas에서는 다양한 방식으로 데이터를 선택하고 추출할 수 있습니다. 기본 인덱싱부터 라벨 기반 인덱싱(loc), 위치 기반 인덱싱(iloc) 그리고 불리언 인덱싱을 통한 조건 필터링까지, 데이터를 원하는 방식으로 다루는 방법을 알아보겠습니다.\n",
    "\n",
    "##**4.1 기본 인덱싱**\n",
    "\n",
    "*   **Series에서의 인덱싱:**\n",
    "\n",
    "  Series는 1차원 데이터 구조로, 인덱스 라벨 또는 정수 위치를 사용해 개별 요소에 접근할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1740193071173,
     "user": {
      "displayName": "이유태",
      "userId": "01951466277766633919"
     },
     "user_tz": -540
    },
    "id": "nQiRNIeJluDG",
    "outputId": "81acd89c-13ca-4774-9763-62c5f58e2400"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series 전체:\n",
      "0    10\n",
      "1    20\n",
      "2    30\n",
      "3    40\n",
      "dtype: int64\n",
      "\n",
      "인덱스 2번 요소: 30\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 기본 인덱스가 자동 할당된 Series 생성\n",
    "s = pd.Series([10, 20, 30, 40])\n",
    "print(\"Series 전체:\")\n",
    "print(s)\n",
    "\n",
    "# 인덱스 번호를 이용한 접근\n",
    "print(\"\\n인덱스 2번 요소:\", s[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eFLOIo5hlxYe"
   },
   "source": [
    "*   **DataFrame에서의 인덱싱:**\n",
    "\n",
    "  DataFrame은 행과 열이 있는 2차원 구조로, 기본적으로 열 이름(라벨)이나 행 번호를 통해 선택할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 50,
     "status": "ok",
     "timestamp": 1740193101821,
     "user": {
      "displayName": "이유태",
      "userId": "01951466277766633919"
     },
     "user_tz": -540
    },
    "id": "Gp0qSF87l2IO",
    "outputId": "5bd4c8c6-c9c8-4f07-bb49-8565396e3b6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "전체 DataFrame:\n",
      "        이름  나이  도시\n",
      "0    Alice  25  서울\n",
      "1      Bob  30  부산\n",
      "2  Charlie  35  대구\n",
      "3    David  40  인천\n"
     ]
    }
   ],
   "source": [
    "# DataFrame 생성\n",
    "data = {\n",
    "    '이름': ['Alice', 'Bob', 'Charlie', 'David'],\n",
    "    '나이': [25, 30, 35, 40],\n",
    "    '도시': ['서울', '부산', '대구', '인천']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(\"\\n전체 DataFrame:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hxK6Eu2jl402"
   },
   "source": [
    "##**4.2 라벨 및 위치 기반 인덱싱: loc, iloc, at, iat**\n",
    "\n",
    "###**4.2.1 loc: 라벨 기반 인덱싱**\n",
    "\n",
    "*   **특징:**\n",
    "\n",
    "  loc는 행과 열의 라벨(이름)을 사용하여 데이터를 선택합니다.\n",
    "\n",
    "  *   슬라이싱 시 끝 인덱스가 포함됩니다.\n",
    "\n",
    "*   **예제:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1740193211694,
     "user": {
      "displayName": "이유태",
      "userId": "01951466277766633919"
     },
     "user_tz": -540
    },
    "id": "qtieph2hmQ_u",
    "outputId": "a4f08ab8-8868-48a2-abc3-8835b3ade373"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "loc를 이용한 행 선택 (0번 행):\n",
      "이름    Alice\n",
      "나이       25\n",
      "도시       서울\n",
      "Name: 0, dtype: object\n",
      "\n",
      "loc를 이용한 특정 열 선택:\n",
      "0    25\n",
      "1    30\n",
      "2    35\n",
      "Name: 나이, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 행 라벨 0번, 1번, ...가 기본 인덱스인 경우\n",
    "print(\"\\nloc를 이용한 행 선택 (0번 행):\")\n",
    "print(df.loc[0])\n",
    "\n",
    "# 행과 열 모두 라벨로 선택 (예: '나이' 열)\n",
    "print(\"\\nloc를 이용한 특정 열 선택:\")\n",
    "print(df.loc[0:2, '나이'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wch-fASCmTQG"
   },
   "source": [
    "###**4.2.2 iloc: 위치 기반 인덱싱**\n",
    "\n",
    "*   **특징:**\n",
    "\n",
    "  iloc는 정수 위치(index)를 사용하여 데이터를 선택합니다.\n",
    "\n",
    "  *   슬라이싱 시 끝 인덱스가 포함되지 않습니다.\n",
    "\n",
    "*   **예제:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1740193247720,
     "user": {
      "displayName": "이유태",
      "userId": "01951466277766633919"
     },
     "user_tz": -540
    },
    "id": "xFguJ_rbmaA2",
    "outputId": "4e67f5b3-ea1f-496b-b60b-152384739d35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iloc를 이용한 행 선택 (첫 2개 행):\n",
      "      이름  나이  도시\n",
      "0  Alice  25  서울\n",
      "1    Bob  30  부산\n",
      "\n",
      "iloc를 이용한 행, 열 선택 (첫 행의 두 번째 열):\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "print(\"\\niloc를 이용한 행 선택 (첫 2개 행):\")\n",
    "print(df.iloc[0:2])\n",
    "\n",
    "# 특정 행과 열의 위치로 선택\n",
    "print(\"\\niloc를 이용한 행, 열 선택 (첫 행의 두 번째 열):\")\n",
    "print(df.iloc[0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LDELyvq7mbwe"
   },
   "source": [
    "###**4.2.3 at과 iat: 단일 요소 접근**\n",
    "\n",
    "*   **at:**\n",
    "\n",
    "  라벨을 사용해 단일 요소에 빠르게 접근합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1740193287418,
     "user": {
      "displayName": "이유태",
      "userId": "01951466277766633919"
     },
     "user_tz": -540
    },
    "id": "VjiEy395mju-",
    "outputId": "6d38f57e-02b0-44da-b34f-3924c75749bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'at'를 이용한 단일 요소 접근 (첫 행의 '도시' 값):\n",
      "서울\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n'at'를 이용한 단일 요소 접근 (첫 행의 '도시' 값):\")\n",
    "print(df.at[0, '도시'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4LOA4xrsmlj-"
   },
   "source": [
    "*   **iat:**\n",
    "\n",
    "  정수 위치를 사용해 단일 요소에 빠르게 접근합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1740193314451,
     "user": {
      "displayName": "이유태",
      "userId": "01951466277766633919"
     },
     "user_tz": -540
    },
    "id": "hu3SA8KjmqRW",
    "outputId": "65ecb818-9e8d-42fc-e97b-37397fef39f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'iat'를 이용한 단일 요소 접근 (첫 행의 두 번째 열 값):\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n'iat'를 이용한 단일 요소 접근 (첫 행의 두 번째 열 값):\")\n",
    "print(df.iat[0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7YZa4_L7msJm"
   },
   "source": [
    "##**4.3 불리언 인덱싱 및 조건 필터링**\n",
    "불리언 인덱싱은 조건식을 사용하여 DataFrame이나 Series에서 특정 조건을 만족하는 행 또는 열을 선택할 때 사용합니다.\n",
    "\n",
    "*   **기본 사용법:**\n",
    "\n",
    "  조건식을 사용하면 동일한 크기의 불리언 시리즈 또는 배열이 생성되고, 이 결과를 인덱스로 사용하여 원하는 데이터를 추출할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1740193377134,
     "user": {
      "displayName": "이유태",
      "userId": "01951466277766633919"
     },
     "user_tz": -540
    },
    "id": "3VTGkdr8m5i3",
    "outputId": "59a7e5b2-d6aa-478b-cdda-5bcb8e244a16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "나이가 30 이상인 데이터:\n",
      "        이름  나이  도시\n",
      "1      Bob  55  부산\n",
      "2  Charlie  35  대구\n",
      "3    David  40  인천\n"
     ]
    }
   ],
   "source": [
    "# 나이가 30 이상인 행 선택\n",
    "df_filtered = df[df['나이'] >= 30]\n",
    "print(\"\\n나이가 30 이상인 데이터:\")\n",
    "print(df_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kPhqI9STm7P-"
   },
   "source": [
    "*   **여러 조건 결합:**\n",
    "\n",
    "  논리 연산자(&, |, ~)를 사용하여 다중 조건을 결합할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1740193403918,
     "user": {
      "displayName": "이유태",
      "userId": "01951466277766633919"
     },
     "user_tz": -540
    },
    "id": "JzmUM0nmnANO",
    "outputId": "b5bcefe7-b2db-43a2-87b5-64e09e24b504"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "나이가 30 이상이면서 도시가 '부산'인 데이터:\n",
      "    이름  나이  도시\n",
      "1  Bob  30  부산\n"
     ]
    }
   ],
   "source": [
    "# 나이가 30 이상이면서 도시가 '부산'인 행 선택\n",
    "df_condition = df[(df['나이'] >= 30) & (df['도시'] == '부산')]\n",
    "print(\"\\n나이가 30 이상이면서 도시가 '부산'인 데이터:\")\n",
    "print(df_condition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SXOnqMJonCd1"
   },
   "source": [
    "*   **Series의 조건 필터링:**\n",
    "\n",
    "  Series에서도 동일하게 조건에 따라 값을 필터링할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1740193431469,
     "user": {
      "displayName": "이유태",
      "userId": "01951466277766633919"
     },
     "user_tz": -540
    },
    "id": "07yIcAn0nG0F",
    "outputId": "9b1e6f65-2c89-4925-9342-b428739332ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "35 이상인 나이 값:\n",
      "2    35\n",
      "3    40\n",
      "Name: 나이, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# '나이' Series에서 35 이상인 값만 선택\n",
    "age_series = df['나이']\n",
    "filtered_age = age_series[age_series >= 35]\n",
    "print(\"\\n35 이상인 나이 값:\")\n",
    "print(filtered_age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zYTqBrjqnJAV"
   },
   "source": [
    "##**4.4 고급 선택 기법 및 주의사항**\n",
    "\n",
    "*   **인덱스 재설정:**\n",
    "\n",
    "  필터링 후 인덱스가 원본과 다르게 흩어질 수 있으므로, 필요 시 `reset_index()` 메서드를 사용하여 인덱스를 재설정할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1740193474289,
     "user": {
      "displayName": "이유태",
      "userId": "01951466277766633919"
     },
     "user_tz": -540
    },
    "id": "jRa0FvMqnRWW",
    "outputId": "af34719c-a8d5-41b0-db40-1bd50d695aac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "인덱스 재설정 후:\n",
      "        이름  나이  도시\n",
      "0      Bob  30  부산\n",
      "1  Charlie  35  대구\n",
      "2    David  40  인천\n"
     ]
    }
   ],
   "source": [
    "df_reset = df_filtered.reset_index(drop=True)\n",
    "print(\"\\n인덱스 재설정 후:\")\n",
    "print(df_reset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cYKRfLSLnTFO"
   },
   "source": [
    "*   **복사본과 뷰:**\n",
    "\n",
    "  인덱싱 또는 슬라이싱 결과가 원본 데이터의 뷰(View)인지 복사본인지에 따라, 값을 수정할 때 주의해야 합니다. 원본 데이터의 변경을 피하려면 copy() 메서드를 사용하여 복사본을 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0VqVNhRInXY2"
   },
   "outputs": [],
   "source": [
    "df_copy = df_filtered.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ViQu5ozxnZpu"
   },
   "source": [
    "*   **문법 주의:**\n",
    "\n",
    "  *   조건식을 작성할 때 각 조건은 반드시 괄호로 묶어야 합니다.\n",
    "\n",
    "  *   논리 연산자를 사용할 때는 Python의 `and`, `or` 대신 `&`, `|`를 사용합니다.\n",
    "\n",
    "##**4.5 요약**\n",
    "\n",
    "*   **기본 인덱싱:**\n",
    "\n",
    "  DataFrame과 Series의 기본 인덱싱은 인덱스 라벨 또는 정수 위치를 사용하여 데이터를 선택합니다.\n",
    "\n",
    "*   **loc와 iloc:**\n",
    "\n",
    "  loc는 라벨 기반 인덱싱, iloc는 정수 위치 기반 인덱싱으로, 목적에 따라 적절한 방법을 선택합니다.\n",
    "  \n",
    "*   **불리언 인덱싱:**\n",
    "\n",
    "  조건식을 통해 특정 조건을 만족하는 데이터만 선택하는 방법으로, 데이터 필터링 및 정제에 매우 유용합니다.\n",
    "  \n",
    "*   **단일 요소 접근:**\n",
    "\n",
    "  at와 iat를 사용하여 단일 값에 빠르게 접근할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame( {\n",
    "    '이름': ['피카츄','라이츄','리자드','리자몽','꼬부기','어니부기'],\n",
    "    '속성': ['전기', '전기', '불','불','물',None], \n",
    "    '색깔': ['노랑', '노랑', None,'빨강','파랑','파랑'],\n",
    "    '순위': [ 5, 2, 6, 1, 4, 3] })\n",
    "\n",
    "df.columns = ['이름', '속성','색깔','순위']\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>이름</th>\n",
       "      <th>속성</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>꼬부기</td>\n",
       "      <td>물</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>어니부기</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     이름    속성\n",
       "4   꼬부기     물\n",
       "5  어니부기  None"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['속성']\n",
    "df[['속성']]\n",
    "df[['이름','순위']]\n",
    "df.loc[ (df['속성'] == '전기') | (df['속성'] == '물')]\n",
    "df.loc[ (df['순위'] <= 4) & (df['색깔'] == '파랑') , ['이름','속성'] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b6ZnYIzpoDDW"
   },
   "source": [
    "#**5. 데이터 전처리 및 정제**\n",
    "데이터 전처리 및 정제는 원시 데이터(raw data)에서 노이즈, 결측치, 중복 데이터, 부적절한 형식 등을 제거하거나 보완하여 분석에 적합한 형태로 변환하는 과정입니다. Pandas는 이러한 작업을 수행하기 위한 다양한 메서드와 기능을 제공합니다.\n",
    "\n",
    "##**5.1 결측치 처리 (Missing Value Handling)**\n",
    "\n",
    "*   **결측치 확인:**\n",
    "\n",
    "  Pandas에서는 `isnull()` 또는 `isna()` 메서드를 이용해 결측치를 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1740193804926,
     "user": {
      "displayName": "이유태",
      "userId": "01951466277766633919"
     },
     "user_tz": -540
    },
    "id": "mc9_LE4loh0N",
    "outputId": "959ca183-a394-41c2-e914-8620e2bcbe8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 데이터:\n",
      "        이름    나이    도시\n",
      "0    Alice  25.0    서울\n",
      "1      Bob   NaN    부산\n",
      "2  Charlie  35.0  None\n",
      "3     None  40.0    인천\n",
      "\n",
      "결측치 확인:\n",
      "      이름     나이     도시\n",
      "0  False  False  False\n",
      "1  False   True  False\n",
      "2  False  False   True\n",
      "3   True  False  False\n",
      "\n",
      "열별 결측치 개수:\n",
      "이름    1\n",
      "나이    1\n",
      "도시    1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 예시 DataFrame 생성\n",
    "data = {'이름': ['Alice', 'Bob', 'Charlie', None],\n",
    "        '나이': [25, None, 35, 40],\n",
    "        '도시': ['서울', '부산', None, '인천']}\n",
    "df = pd.DataFrame(data)\n",
    "print(\"원본 데이터:\")\n",
    "print(df)\n",
    "print(\"\\n결측치 확인:\")\n",
    "print(df.isnull())\n",
    "print(\"\\n열별 결측치 개수:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2MlFVt6solNO"
   },
   "source": [
    "*   **결측치 제거:**\n",
    "\n",
    "  `dropna()` 메서드를 사용하여 결측치가 포함된 행이나 열을 제거할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1740193843209,
     "user": {
      "displayName": "이유태",
      "userId": "01951466277766633919"
     },
     "user_tz": -540
    },
    "id": "_O1wlXlqorHO",
    "outputId": "3ef73168-02f8-4e18-d2f4-8f91241aad75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "결측치가 있는 행 제거:\n",
      "      이름    나이  도시\n",
      "0  Alice  25.0  서울\n",
      "\n",
      "'나이' 열에 결측치가 있는 행 제거:\n",
      "        이름    나이    도시\n",
      "0    Alice  25.0    서울\n",
      "2  Charlie  35.0  None\n",
      "3     None  40.0    인천\n"
     ]
    }
   ],
   "source": [
    "# 결측치가 있는 행 제거\n",
    "df_drop = df.dropna()\n",
    "print(\"\\n결측치가 있는 행 제거:\")\n",
    "print(df_drop)\n",
    "\n",
    "# 특정 열에 결측치가 있는 행만 제거 (예: '나이' 열)\n",
    "df_drop_age = df.dropna(subset=['나이'])\n",
    "print(\"\\n'나이' 열에 결측치가 있는 행 제거:\")\n",
    "print(df_drop_age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YD-nuHvcoteO"
   },
   "source": [
    "*   **결측치 대체:**\n",
    "\n",
    "  `fillna()` 메서드를 사용하여 결측치를 특정 값이나 평균, 중앙값 등으로 채울 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1740193873889,
     "user": {
      "displayName": "이유태",
      "userId": "01951466277766633919"
     },
     "user_tz": -540
    },
    "id": "13mAPoyeoy11",
    "outputId": "00c107d2-21d2-4bae-9437-ce6c9b0f7e76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "모든 결측치를 0으로 대체:\n",
      "        이름    나이  도시\n",
      "0    Alice  25.0  서울\n",
      "1      Bob   0.0  부산\n",
      "2  Charlie  35.0   0\n",
      "3        0  40.0  인천\n",
      "\n",
      "'나이' 열의 결측치를 평균으로 대체:\n",
      "        이름         나이    도시\n",
      "0    Alice  25.000000    서울\n",
      "1      Bob  33.333333    부산\n",
      "2  Charlie  35.000000  None\n",
      "3     None  40.000000    인천\n"
     ]
    }
   ],
   "source": [
    "# 모든 결측치를 0으로 대체\n",
    "df_filled = df.fillna(0)\n",
    "print(\"\\n모든 결측치를 0으로 대체:\")\n",
    "print(df_filled)\n",
    "\n",
    "# '나이' 열의 결측치를 해당 열의 평균으로 대체\n",
    "mean_age = df['나이'].mean()\n",
    "df['나이'] = df['나이'].fillna(mean_age)\n",
    "print(\"\\n'나이' 열의 결측치를 평균으로 대체:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s58slGggo1al"
   },
   "source": [
    "##**5.2 중복 데이터 처리 (Handling Duplicates)**\n",
    "\n",
    "*   **중복 데이터 확인:**\n",
    "\n",
    "  `duplicated()` 메서드를 사용하여 DataFrame 내 중복 행을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1740193916989,
     "user": {
      "displayName": "이유태",
      "userId": "01951466277766633919"
     },
     "user_tz": -540
    },
    "id": "FEHpa6JXo9Ze",
    "outputId": "19101252-5394-407d-aee3-6d089d2ccc64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "중복 데이터 확인:\n",
      "0    False\n",
      "1    False\n",
      "2     True\n",
      "3    False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "# 예시 DataFrame (중복 포함)\n",
    "data_dup = {'이름': ['Alice', 'Bob', 'Alice', 'David'],\n",
    "            '나이': [25, 30, 25, 40],\n",
    "            '도시': ['서울', '부산', '서울', '인천']}\n",
    "df_dup = pd.DataFrame(data_dup)\n",
    "print(\"\\n중복 데이터 확인:\")\n",
    "print(df_dup.duplicated())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rbj2c3fgo_UF"
   },
   "source": [
    "*   **중복 데이터 제거:**\n",
    "\n",
    "  `drop_duplicates(`) 메서드를 사용하여 중복된 행을 제거할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 53,
     "status": "ok",
     "timestamp": 1740193950707,
     "user": {
      "displayName": "이유태",
      "userId": "01951466277766633919"
     },
     "user_tz": -540
    },
    "id": "TPvqZPuypFb1",
    "outputId": "d842b8e1-b447-4c09-b1e4-66b8e122999d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "중복 데이터 제거:\n",
      "      이름  나이  도시\n",
      "0  Alice  25  서울\n",
      "1    Bob  30  부산\n",
      "3  David  40  인천\n"
     ]
    }
   ],
   "source": [
    "df_no_dup = df_dup.drop_duplicates()\n",
    "print(\"\\n중복 데이터 제거:\")\n",
    "print(df_no_dup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uoAIuBYlpH0d"
   },
   "source": [
    "##**5.3 데이터 타입 변환 및 문자열 처리**\n",
    "\n",
    "*   **데이터 타입 변환:**\n",
    "\n",
    "  `astype()` 메서드를 사용하여 열의 데이터 타입을 변경할 수 있습니다. 예를 들어, 숫자형 문자열을 정수나 실수로 변환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1740193991038,
     "user": {
      "displayName": "이유태",
      "userId": "01951466277766633919"
     },
     "user_tz": -540
    },
    "id": "558bGfEtpPXm",
    "outputId": "5dc1b378-6dba-438e-c197-eda8bdc99ece"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "원본 데이터 타입:\n",
      "점수    object\n",
      "dtype: object\n",
      "\n",
      "변환 후 데이터 타입:\n",
      "점수    int32\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df_type = pd.DataFrame({'점수': ['85', '90', '78']})\n",
    "print(\"\\n원본 데이터 타입:\")\n",
    "print(df_type.dtypes)\n",
    "\n",
    "# 문자열을 정수형으로 변환\n",
    "df_type['점수'] = df_type['점수'].astype(int)\n",
    "print(\"\\n변환 후 데이터 타입:\")\n",
    "print(df_type.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q_pGdkkdpRWT"
   },
   "source": [
    "*   **문자열 처리:**\n",
    "\n",
    "  Pandas의 문자열 관련 메서드(`str`)를 사용하여 텍스트 데이터를 처리할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1740194024323,
     "user": {
      "displayName": "이유태",
      "userId": "01951466277766633919"
     },
     "user_tz": -540
    },
    "id": "7RELfM-LpXqt",
    "outputId": "4c9117ff-5047-4adb-a2bb-d2ea43afa32e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        이름\n",
      "0   Alice \n",
      "1      Bob\n",
      "2  Charlie\n",
      "        이름\n",
      "0    Alice\n",
      "1      Bob\n",
      "2  Charlie\n",
      "\n",
      "문자열 처리 후:\n",
      "        이름\n",
      "0    ALICE\n",
      "1      BOB\n",
      "2  CHARLIE\n"
     ]
    }
   ],
   "source": [
    "df_str = pd.DataFrame({'이름': [' Alice ', 'Bob', 'Charlie']})\n",
    "print(df_str)\n",
    "# 공백 제거\n",
    "df_str['이름'] = df_str['이름'].str.strip()\n",
    "print(df_str)\n",
    "# 대문자 변환\n",
    "df_str['이름'] = df_str['이름'].str.upper()\n",
    "print(\"\\n문자열 처리 후:\")\n",
    "print(df_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QATpOwz8pZq1"
   },
   "source": [
    "##**5.4 파생 변수 생성 및 데이터 변환**\n",
    "\n",
    "*   **파생 변수 생성:**\n",
    "\n",
    "  기존의 열을 기반으로 새로운 열(파생 변수)을 생성하여, 추가적인 정보를 도출할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 52,
     "status": "ok",
     "timestamp": 1740194060397,
     "user": {
      "displayName": "이유태",
      "userId": "01951466277766633919"
     },
     "user_tz": -540
    },
    "id": "rhT4u6BNpgWd",
    "outputId": "49fd1fb4-d8d4-4d3f-f018-7b2ba10ed267"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "파생 변수 '연령대' 추가:\n",
      "        이름         나이    도시 연령대\n",
      "0    Alice  25.000000    서울  청년\n",
      "1      Bob  33.333333    부산  중년\n",
      "2  Charlie  35.000000  None  중년\n",
      "3     None  40.000000    인천  장년\n"
     ]
    }
   ],
   "source": [
    "# 예시: '나이' 열을 이용하여 '연령대' 열 생성\n",
    "df['연령대'] = pd.cut(df['나이'], bins=[0, 29, 39, 100], labels=['청년', '중년', '장년'])\n",
    "print(\"\\n파생 변수 '연령대' 추가:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0CFoRz2vpiXN"
   },
   "source": [
    "*   **데이터 정규화 및 스케일링:**\n",
    "\n",
    "  경우에 따라 데이터 범위를 조정(예: min-max scaling, 표준화)하여 분석에 적합하게 변환할 수 있습니다. Pandas와 NumPy를 활용하여 간단한 정규화 작업을 수행할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1740194089861,
     "user": {
      "displayName": "이유태",
      "userId": "01951466277766633919"
     },
     "user_tz": -540
    },
    "id": "UWZfjGOwpnod",
    "outputId": "ab179e67-5e1f-45cf-831e-3bbcbdc26cc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Min-Max 정규화:\n",
      "   점수    정규화 점수\n",
      "0  85  0.411765\n",
      "1  90  0.705882\n",
      "2  78  0.000000\n",
      "3  95  1.000000\n",
      "4  88  0.588235\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 예시: '점수' 열의 min-max 정규화\n",
    "df_score = pd.DataFrame({'점수': [85, 90, 78, 95, 88]})\n",
    "df_score['정규화 점수'] = (df_score['점수'] - df_score['점수'].min()) / (df_score['점수'].max() - df_score['점수'].min())\n",
    "print(\"\\nMin-Max 정규화:\")\n",
    "print(df_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c0UoQ0mhpqEF"
   },
   "source": [
    "##**5.5 데이터 전처리 실습 팁 및 주의사항**\n",
    "\n",
    "*   **데이터 백업:**\n",
    "\n",
    "  전처리 작업 전 원본 데이터를 백업하여, 필요 시 원본으로 복원할 수 있도록 합니다.\n",
    "\n",
    "*   **연속적인 작업:**\n",
    "\n",
    "  여러 전처리 과정을 순차적으로 적용할 때는, 각 단계별로 결과를 확인하여 의도한 대로 변환되었는지 검증하는 것이 중요합니다.\n",
    "\n",
    "*   **메모리 사용:**\n",
    "\n",
    "  대용량 데이터셋의 경우, 불필요한 복사본을 만들지 않도록 주의하며, in-place 연산(`inplace=True`)을 적절히 활용합니다.\n",
    "  \n",
    "*   **데이터 문서화:**\n",
    "\n",
    "  전처리 과정과 사용한 방법을 문서화하여, 후속 분석이나 협업 시 참고할 수 있도록 기록합니다.\n",
    "\n",
    "##**5.6 요약**\n",
    "\n",
    "*   **결측치 처리:**\n",
    "\n",
    "  `isnull()`, `dropna()`, `fillna(`)를 통해 결측치를 확인, 제거 또는 대체합니다.\n",
    "\n",
    "*   **중복 데이터 처리:**\n",
    "\n",
    "  `duplicated()`, `drop_duplicates()`를 사용하여 중복된 데이터를 관리합니다.\n",
    "\n",
    "*   **데이터 타입 변환 및 문자열 처리:**\n",
    "\n",
    "  `astype()`과 `str` 메서드를 활용해 데이터 형식을 변경하고 텍스트 데이터를 정제합니다.\n",
    "\n",
    "*   **파생 변수 생성 및 데이터 변환:**\n",
    "\n",
    "  기존 데이터를 바탕으로 새로운 변수를 도출하거나, 데이터 스케일링 등의 변환 작업을 수행하여 분석에 적합한 형태로 만듭니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PXbPfYUWqbNd"
   },
   "source": [
    "#**6. 데이터 병합, 결합 및 분할**\n",
    "Pandas에서는 여러 개의 DataFrame이나 Series를 하나의 데이터셋으로 통합하거나, 하나의 데이터셋을 원하는 기준에 따라 분할할 수 있는 다양한 기능을 제공합니다. 이 장에서는 데이터 병합(merge, join), 데이터 결합(concatenation, append) 및 데이터 분할(split, groupby 활용) 방법을 예제와 함께 살펴봅니다.\n",
    "\n",
    "##**6.1 데이터 병합 (Merging)**\n",
    "데이터 병합은 두 개 이상의 DataFrame을 공통 키(또는 인덱스)를 기준으로 결합하는 작업입니다. 대표적으로 **pd.merge()** 함수와 **join()** 메서드를 사용합니다.\n",
    "\n",
    "###**6.1.1 pd.merge() 함수**\n",
    "\n",
    "*   **기본 개념:**\n",
    "\n",
    "  두 DataFrame에서 공통된 열(또는 인덱스)을 기준으로 내부(inner), 외부(outer), 왼쪽(left) 또는 오른쪽(right) 병합을 수행할 수 있습니다.\n",
    "\n",
    "*   **예제:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1740199724269,
     "user": {
      "displayName": "이유태",
      "userId": "01951466277766633919"
     },
     "user_tz": -540
    },
    "id": "ZBcxfXm__Gsx",
    "outputId": "40bc2222-f502-4e1f-b49b-c4d07850f8a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "내부 병합 결과:\n",
      "   키       이름  나이\n",
      "0  3  Charlie  35\n",
      "1  4    David  40\n",
      "\n",
      "왼쪽 병합 결과:\n",
      "   키       이름    나이\n",
      "0  1    Alice   NaN\n",
      "1  2      Bob   NaN\n",
      "2  3  Charlie  35.0\n",
      "3  4    David  40.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 예시 DataFrame 생성\n",
    "df1 = pd.DataFrame({\n",
    "    '키': [1, 2, 3, 4],\n",
    "    '이름': ['Alice', 'Bob', 'Charlie', 'David']\n",
    "})\n",
    "\n",
    "df2 = pd.DataFrame({\n",
    "    '키': [3, 4, 5, 6],\n",
    "    '나이': [35, 40, 45, 50]\n",
    "})\n",
    "\n",
    "# 내부 병합 (공통된 키만 결합)\n",
    "inner_merge = pd.merge(df1, df2, on='키', how='inner')\n",
    "print(\"내부 병합 결과:\")\n",
    "print(inner_merge)\n",
    "# 출력: 키가 3, 4인 행이 결합됨\n",
    "\n",
    "# 왼쪽 병합 (df1의 모든 행 유지)\n",
    "left_merge = pd.merge(df1, df2, on='키', how='left')\n",
    "print(\"\\n왼쪽 병합 결과:\")\n",
    "print(left_merge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "09IwNmWX_LHC"
   },
   "source": [
    "###**6.1.2 DataFrame.join() 메서드**\n",
    "\n",
    "*   **기본 개념:**\n",
    "\n",
    "  인덱스를 기준으로 두 DataFrame을 결합하는 방법입니다. 주로 인덱스가 이미 설정되어 있는 경우에 유용합니다.\n",
    "\n",
    "*   **예제:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 55,
     "status": "ok",
     "timestamp": 1740199759012,
     "user": {
      "displayName": "이유태",
      "userId": "01951466277766633919"
     },
     "user_tz": -540
    },
    "id": "wWAnafSn_Pg6",
    "outputId": "86f8d922-312b-4346-b3b4-5d455554a824"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame.join()을 이용한 결합:\n",
      "        이름  점수    나이\n",
      "1    Alice  85   NaN\n",
      "2      Bob  90  25.0\n",
      "3  Charlie  95  30.0\n"
     ]
    }
   ],
   "source": [
    "# 예시 DataFrame 생성 (인덱스를 공통 키로 사용)\n",
    "df1 = pd.DataFrame({\n",
    "    '이름': ['Alice', 'Bob', 'Charlie'],\n",
    "    '점수': [85, 90, 95]\n",
    "}, index=[1, 2, 3])\n",
    "\n",
    "df2 = pd.DataFrame({\n",
    "    '나이': [25, 30, 35]\n",
    "}, index=[2, 3, 4])\n",
    "\n",
    "# 인덱스를 기준으로 결합 (기본적으로 왼쪽 인덱스를 기준)\n",
    "joined = df1.join(df2, how='left')\n",
    "print(\"\\nDataFrame.join()을 이용한 결합:\")\n",
    "print(joined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mJFHD7-A_T8h"
   },
   "source": [
    "##**6.2 데이터 결합 (Concatenation)**\n",
    "여러 개의 DataFrame이나 Series를 위아래(행 방향) 또는 좌우(열 방향)로 연결할 때는 **pd.concat()** 함수를 사용합니다.\n",
    "\n",
    "###**6.2.1 pd.concat() 함수**\n",
    "\n",
    "*   **기본 개념:**\n",
    "\n",
    "  리스트 형태의 DataFrame이나 Series를 하나로 이어붙입니다. `axis` 매개변수를 0(행 결합) 또는 1(열 결합)로 지정할 수 있습니다.\n",
    "\n",
    "*   **예제:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1740199876581,
     "user": {
      "displayName": "이유태",
      "userId": "01951466277766633919"
     },
     "user_tz": -540
    },
    "id": "zs1B1glI_rjZ",
    "outputId": "482e3908-2485-42ac-dcb8-7ea6eedd0941"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "행 방향 결합 결과:\n",
      "   A\n",
      "0  1\n",
      "1  2\n",
      "2  3\n",
      "3  4\n",
      "4  5\n",
      "5  6\n",
      "\n",
      "열 방향 결합 결과:\n",
      "   A  B\n",
      "0  1  7\n",
      "1  2  8\n",
      "2  3  9\n"
     ]
    }
   ],
   "source": [
    "# 예시 DataFrame 생성\n",
    "df_a = pd.DataFrame({'A': [1, 2, 3]})\n",
    "df_b = pd.DataFrame({'A': [4, 5, 6]})\n",
    "\n",
    "# 행 방향으로 결합 (세로로 이어붙이기)\n",
    "concat_row = pd.concat([df_a, df_b], axis=0, ignore_index=True)\n",
    "print(\"행 방향 결합 결과:\")\n",
    "print(concat_row)\n",
    "\n",
    "# 열 방향으로 결합 (좌우로 이어붙이기)\n",
    "df_c = pd.DataFrame({'B': [7, 8, 9]})\n",
    "concat_col = pd.concat([df_a, df_c], axis=1)\n",
    "print(\"\\n열 방향 결합 결과:\")\n",
    "print(concat_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jaNggvSo_zBJ"
   },
   "source": [
    "##**6.3 데이터 분할 (Splitting)**\n",
    "데이터 분할은 하나의 DataFrame을 조건, 그룹, 또는 인덱스 기준으로 여러 개의 부분으로 나누는 작업을 의미합니다.\n",
    "\n",
    "###**6.3.1 GroupBy를 활용한 분할**\n",
    "\n",
    "*   **기본 개념:**\n",
    "\n",
    "  GroupBy는 데이터를 특정 열의 값에 따라 그룹으로 나눈 후, 각 그룹별로 집계(aggregation)나 변환(transform) 작업을 수행할 수 있게 합니다.\n",
    "\n",
    "*   **예제:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 63,
     "status": "ok",
     "timestamp": 1740200031479,
     "user": {
      "displayName": "이유태",
      "userId": "01951466277766633919"
     },
     "user_tz": -540
    },
    "id": "QmurqDdZAR8B",
    "outputId": "07e4980c-42ca-4d6d-c99a-2d67db1687a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 데이터:\n",
      "        이름  과목  점수\n",
      "0    Alice  수학  85\n",
      "1      Bob  영어  90\n",
      "2  Charlie  수학  78\n",
      "3    David  영어  88\n",
      "4      Eve  수학  92\n",
      "\n",
      "과목별 평균 점수:\n",
      "과목\n",
      "수학    85.0\n",
      "영어    89.0\n",
      "Name: 점수, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 예시 DataFrame 생성\n",
    "data = {\n",
    "    '이름': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n",
    "    '과목': ['수학', '영어', '수학', '영어', '수학'],\n",
    "    '점수': [85, 90, 78, 88, 92]\n",
    "}\n",
    "df_scores = pd.DataFrame(data)\n",
    "print(\"원본 데이터:\")\n",
    "print(df_scores)\n",
    "\n",
    "# 과목별 그룹화 후 평균 점수 계산\n",
    "group_mean = df_scores.groupby('과목')['점수'].mean()\n",
    "print(\"\\n과목별 평균 점수:\")\n",
    "print(group_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "frTD_wTlAVgh"
   },
   "source": [
    "###**6.3.2 인덱스 또는 조건에 따른 분할**\n",
    "\n",
    "*   **DataFrame 분할:**\n",
    "\n",
    "  특정 조건을 만족하는 행만 선택하여 별도의 DataFrame으로 분할할 수 있습니다.\n",
    "\n",
    "*   **예제:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1740200063978,
     "user": {
      "displayName": "이유태",
      "userId": "01951466277766633919"
     },
     "user_tz": -540
    },
    "id": "_8fL5b7qAaNx",
    "outputId": "ac0928ac-cfa1-4c8f-d73b-3ea7eb3c3c49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "85점 이상인 데이터:\n",
      "      이름  과목  점수\n",
      "0  Alice  수학  85\n",
      "1    Bob  영어  90\n",
      "3  David  영어  88\n",
      "4    Eve  수학  92\n"
     ]
    }
   ],
   "source": [
    "# '점수'가 85 이상인 행만 선택하여 분할\n",
    "high_scores = df_scores[df_scores['점수'] >= 85]\n",
    "print(\"\\n85점 이상인 데이터:\")\n",
    "print(high_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p29niukLAfJS"
   },
   "source": [
    "##**6.4 유의사항 및 활용 팁**\n",
    "\n",
    "*   **키(인덱스) 정렬 및 중복 확인:**\n",
    "\n",
    "  병합 및 결합 전에 공통 키(또는 인덱스)가 올바르게 정렬되어 있고 중복이 없는지 확인하는 것이 좋습니다.\n",
    "\n",
    "*   **결합 시 인덱스 관리:**\n",
    "\n",
    "  결합 후 인덱스가 중복되거나 불연속적일 수 있으므로, 필요에 따라 `ignore_index=True` 옵션이나 `reset_index()` 메서드를 활용하여 인덱스를 재설정합니다.\n",
    "  \n",
    "*   **데이터 분할 후 집계:**\n",
    "\n",
    "  roupBy를 통한 분할 작업 후, 각 그룹에 대해 적절한 집계 함수(예: mean, sum, count 등)를 사용하면, 데이터의 특성을 쉽게 파악할 수 있습니다.\n",
    "\n",
    "##**6.5 요약**\n",
    "\n",
    "*   **데이터 병합:**\n",
    "\n",
    "  pd.merge()와 DataFrame.join()을 통해 공통 키를 기준으로 여러 데이터셋을 결합할 수 있습니다.\n",
    "\n",
    "*   **데이터 결합:**\n",
    "\n",
    "  pd.concat()를 사용하여 행 또는 열 방향으로 DataFrame이나 Series를 연결합니다.\n",
    "  \n",
    "*   **데이터 분할:**\n",
    "\n",
    "  GroupBy, 조건 필터링 등을 활용하여 데이터를 원하는 기준에 따라 분할할 수 있습니다.\n",
    "  \n",
    "*   **실제 활용:**\n",
    "\n",
    "  이러한 기능들은 데이터 전처리, 통계 분석, 피벗 테이블 작성 등 다양한 데이터 분석 작업에서 핵심적으로 사용됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bZZc9WQkCerZ"
   },
   "source": [
    "#**7. 시계열 데이터 처리**\n",
    "시계열 데이터(time series data)는 일정한 시간 간격으로 수집된 데이터로, Pandas는 이러한 데이터를 효율적으로 다루기 위한 다양한 기능을 제공합니다. 본 장에서는 시계열 데이터 생성, 인덱스 설정, 리샘플링, 이동 평균 계산, 시간대 변환 등 주요 기능과 함께 실제 예제 코드를 통해 사용법을 자세히 살펴봅니다.\n",
    "\n",
    "##**7.1 시계열 데이터의 이해**\n",
    "\n",
    "*   **정의:**\n",
    "\n",
    "  시계열 데이터는 시간에 따른 변화 추이를 분석하기 위한 데이터로, 주식 가격, 기온, 판매량, 센서 데이터 등 다양한 분야에서 활용됩니다.\n",
    "\n",
    "*   **특징:**\n",
    "\n",
    "  *   **시간 순서 유지:** 데이터가 시간 순서대로 정렬되어 있으며, 순서가 분석 결과에 중요한 영향을 미칩니다.\n",
    "\n",
    "  *   **주기성 및 계절성:** 특정 기간마다 반복되는 패턴이 있을 수 있습니다.\n",
    "\n",
    "  *   **추세:** 전반적인 상승 또는 하강 추세를 보일 수 있습니다.\n",
    "\n",
    "##**7.2 시계열 데이터 생성 및 인덱스 설정**\n",
    "Pandas에서는 pd.date_range() 함수를 사용하여 일정 기간의 날짜 범위를 쉽게 생성할 수 있습니다. 생성한 날짜 범위를 DataFrame의 인덱스로 설정하면 시계열 데이터 처리가 용이해집니다.\n",
    "\n",
    "*   **예제: 날짜 범위 생성 및 인덱스 설정**\n",
    "\n",
    "  *   **설명:**\n",
    "\n",
    "      아래 예제에서는 2023년 1월 1일부터 100일 동안의 날짜 범위를 생성하고, 이를 인덱스로 하여 무작위 값이 채워진 DataFrame을 생성하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1740200888008,
     "user": {
      "displayName": "이유태",
      "userId": "01951466277766633919"
     },
     "user_tz": -540
    },
    "id": "ae-unijaDjL5",
    "outputId": "1307abf1-5aeb-45d7-b6a8-bf40589b9be6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시계열 DataFrame (상위 5개):\n",
      "                 데이터\n",
      "2023-01-01  1.579063\n",
      "2023-01-02  0.645666\n",
      "2023-01-03 -0.188191\n",
      "2023-01-04 -1.253606\n",
      "2023-01-05  0.395031\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 2023년 1월 1일부터 100일 간격의 날짜 생성\n",
    "date_rng = pd.date_range(start='2023-01-01', periods=100, freq='D')\n",
    "\n",
    "# 날짜 인덱스를 활용하여 DataFrame 생성\n",
    "df_ts = pd.DataFrame({'데이터': np.random.randn(100)}, index=date_rng)\n",
    "print(\"시계열 DataFrame (상위 5개):\")\n",
    "print(df_ts.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iPzAGtGdDntR"
   },
   "source": [
    "##**7.3 리샘플링 (Resampling)**\n",
    "리샘플링은 시계열 데이터를 다른 시간 간격으로 변환하는 작업입니다. 예를 들어, 일별 데이터를 주별 또는 월별 데이터로 집계할 수 있습니다.\n",
    "\n",
    "*   **예제: 일별 데이터를 주별 평균으로 리샘플링**\n",
    "\n",
    "  *   **설명:**\n",
    "\n",
    "      `resample('W')`를 사용하여 일별 데이터를 주 단위로 재구성하고, 각 주의 평균을 계산합니다. 리샘플링은 집계(aggregation) 함수(mean, sum, max 등)와 함께 사용됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 58,
     "status": "ok",
     "timestamp": 1740200943508,
     "user": {
      "displayName": "이유태",
      "userId": "01951466277766633919"
     },
     "user_tz": -540
    },
    "id": "f7HAKjf2DwyB",
    "outputId": "f6375900-5fc5-412f-c5cc-22fa7dc5e524"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "주별 평균 데이터:\n",
      "                 데이터\n",
      "2023-01-01  1.579063\n",
      "2023-01-08 -0.057714\n",
      "2023-01-15 -0.298077\n",
      "2023-01-22  0.066422\n",
      "2023-01-29 -0.109167\n",
      "2023-02-05 -0.296780\n",
      "2023-02-12 -0.133720\n",
      "2023-02-19 -0.029129\n",
      "2023-02-26  0.099938\n",
      "2023-03-05  0.163908\n",
      "2023-03-12  0.325155\n",
      "2023-03-19 -0.370898\n",
      "2023-03-26  0.048666\n",
      "2023-04-02  0.910921\n",
      "2023-04-09  0.009010\n",
      "2023-04-16 -1.529413\n"
     ]
    }
   ],
   "source": [
    "# 주별 평균 계산 (W: 주 단위)\n",
    "weekly_avg = df_ts.resample('W').mean()\n",
    "print(\"\\n주별 평균 데이터:\")\n",
    "print(weekly_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a6IcTiHSD0uA"
   },
   "source": [
    "##**7.4 이동 윈도우 (Rolling Window) 연산**\n",
    "이동 윈도우 연산은 시계열 데이터의 일정 기간 동안의 통계값(예: 이동 평균, 이동 합계 등)을 계산하는 방법입니다.\n",
    "\n",
    "*   **예제: 7일 이동 평균 계산**\n",
    "\n",
    "  *   **설명:**\n",
    "\n",
    "      `rolling(window=7)`을 사용하여 7일 간격의 데이터를 묶고, 그 평균을 계산합니다. 이동 평균은 데이터의 단기 변동성을 줄이고 장기 추세를 파악하는 데 유용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1740200992424,
     "user": {
      "displayName": "이유태",
      "userId": "01951466277766633919"
     },
     "user_tz": -540
    },
    "id": "jLAc5KUOD8y4",
    "outputId": "5e531e57-69d5-4189-9045-6127aa1914b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "7일 이동 평균 적용 결과 (상위 10개):\n",
      "                 데이터   7일_이동평균\n",
      "2023-01-01  1.579063       NaN\n",
      "2023-01-02  0.645666       NaN\n",
      "2023-01-03 -0.188191       NaN\n",
      "2023-01-04 -1.253606       NaN\n",
      "2023-01-05  0.395031       NaN\n",
      "2023-01-06 -0.451940       NaN\n",
      "2023-01-07  0.315436  0.148780\n",
      "2023-01-08  0.133610 -0.057714\n",
      "2023-01-09  1.109430  0.008538\n",
      "2023-01-10 -0.583491 -0.047933\n"
     ]
    }
   ],
   "source": [
    "# 7일 이동 평균 계산\n",
    "df_ts['7일_이동평균'] = df_ts['데이터'].rolling(window=7).mean()\n",
    "print(\"\\n7일 이동 평균 적용 결과 (상위 10개):\")\n",
    "print(df_ts.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T8o29Rw-D-ro"
   },
   "source": [
    "##**7.5 시간대 변환 및 시계열 데이터 정렬**\n",
    "시계열 데이터는 서로 다른 시간대를 포함할 수 있으며, Pandas는 이를 쉽게 변환할 수 있도록 지원합니다.\n",
    "\n",
    "*   **시간대 정보 추가 및 변환 예제:**\n",
    "\n",
    "  *   **설명:**\n",
    "\n",
    "      `tz_localize()`를 사용하여 데이터에 처음으로 시간대 정보를 추가하고, `tz_convert()`를 통해 원하는 시간대로 변경할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 55,
     "status": "ok",
     "timestamp": 1740201044142,
     "user": {
      "displayName": "이유태",
      "userId": "01951466277766633919"
     },
     "user_tz": -540
    },
    "id": "wFoCqiTLEJaA",
    "outputId": "7a42c112-2387-4a8b-bbad-dba369be6434"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "UTC 시간대 적용:\n",
      "                                데이터  7일_이동평균\n",
      "2023-01-01 00:00:00+00:00  1.579063      NaN\n",
      "2023-01-02 00:00:00+00:00  0.645666      NaN\n",
      "2023-01-03 00:00:00+00:00 -0.188191      NaN\n",
      "2023-01-04 00:00:00+00:00 -1.253606      NaN\n",
      "2023-01-05 00:00:00+00:00  0.395031      NaN\n",
      "\n",
      "아시아/서울 시간대로 변환:\n",
      "                                데이터  7일_이동평균\n",
      "2023-01-01 09:00:00+09:00  1.579063      NaN\n",
      "2023-01-02 09:00:00+09:00  0.645666      NaN\n",
      "2023-01-03 09:00:00+09:00 -0.188191      NaN\n",
      "2023-01-04 09:00:00+09:00 -1.253606      NaN\n",
      "2023-01-05 09:00:00+09:00  0.395031      NaN\n"
     ]
    }
   ],
   "source": [
    "# 현재 시계열 데이터에 시간대 정보 추가 (UTC로 설정)\n",
    "df_ts = df_ts.tz_localize('UTC')\n",
    "print(\"\\nUTC 시간대 적용:\")\n",
    "print(df_ts.head())\n",
    "\n",
    "# UTC를 다른 시간대로 변환 (예: 아시아/서울)\n",
    "df_ts = df_ts.tz_convert('Asia/Seoul')\n",
    "print(\"\\n아시아/서울 시간대로 변환:\")\n",
    "print(df_ts.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZJy-b8BfGW3Q"
   },
   "source": [
    "##**7.6 기타 시계열 관련 기능**\n",
    "\n",
    "*   **시차 (Shift) 및 변화율 계산:**\n",
    "\n",
    "  시계열 데이터에서 이전 기간과의 차이나 변화율을 계산할 때 shift() 메서드를 사용합니다.\n",
    "\n",
    "  *   **설명:**\n",
    "\n",
    "      `shift(1)`은 모든 값을 1일 뒤로 이동시켜, 현재 값과 전일 값을 비교할 수 있도록 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 74,
     "status": "ok",
     "timestamp": 1740201659560,
     "user": {
      "displayName": "이유태",
      "userId": "01951466277766633919"
     },
     "user_tz": -540
    },
    "id": "y2hu_AlGGfrg",
    "outputId": "8da2cf59-ed62-4522-b653-92175610e995"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "전일 대비 변화량 계산:\n",
      "                                데이터   7일_이동평균    전일_데이터       변화량\n",
      "2023-01-01 09:00:00+09:00  1.579063       NaN       NaN       NaN\n",
      "2023-01-02 09:00:00+09:00  0.645666       NaN  1.579063 -0.933398\n",
      "2023-01-03 09:00:00+09:00 -0.188191       NaN  0.645666 -0.833856\n",
      "2023-01-04 09:00:00+09:00 -1.253606       NaN -0.188191 -1.065416\n",
      "2023-01-05 09:00:00+09:00  0.395031       NaN -1.253606  1.648637\n",
      "2023-01-06 09:00:00+09:00 -0.451940       NaN  0.395031 -0.846971\n",
      "2023-01-07 09:00:00+09:00  0.315436  0.148780 -0.451940  0.767376\n",
      "2023-01-08 09:00:00+09:00  0.133610 -0.057714  0.315436 -0.181827\n",
      "2023-01-09 09:00:00+09:00  1.109430  0.008538  0.133610  0.975820\n",
      "2023-01-10 09:00:00+09:00 -0.583491 -0.047933  1.109430 -1.692920\n"
     ]
    }
   ],
   "source": [
    "# 데이터의 1일 전 값을 참조하여 변화량 계산\n",
    "df_ts['전일_데이터'] = df_ts['데이터'].shift(1)\n",
    "df_ts['변화량'] = df_ts['데이터'] - df_ts['전일_데이터']\n",
    "print(\"\\n전일 대비 변화량 계산:\")\n",
    "print(df_ts.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hUSZLUecGjj4"
   },
   "source": [
    "*   **시계열 인덱스 정렬:**\n",
    "\n",
    "  데이터가 시간 순서대로 정렬되어 있지 않으면, sort_index()를 사용해 인덱스를 정렬합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7qBr_0eOGoGq"
   },
   "outputs": [],
   "source": [
    "# 인덱스가 날짜인 경우, 정렬\n",
    "df_ts = df_ts.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8NgwyJ4XGtrA"
   },
   "source": [
    "##**7.7 요약**\n",
    "\n",
    "*   **시계열 데이터 생성:**\n",
    "\n",
    "  `pd.date_range()`를 활용하여 날짜 범위를 생성하고, 이를 인덱스로 설정하여 DataFrame을 구성합니다.\n",
    "\n",
    "*   **리샘플링:**\n",
    "\n",
    "  데이터를 원하는 시간 간격(주, 월, 분기 등)으로 집계하여, 데이터의 추세를 파악합니다.\n",
    "  \n",
    "*   **이동 윈도우 연산:**\n",
    "\n",
    "  이동 평균 등의 통계 값을 계산해 단기 변동성을 줄이고, 장기 추세를 분석합니다.\n",
    "\n",
    "*   **시간대 변환:**\n",
    "\n",
    "  `tz_localize()`와 `tz_convert()`를 통해 서로 다른 시간대를 다루고 변환할 수 있습니다.\n",
    "\n",
    "*   **시차 및 변화율 계산:**\n",
    "\n",
    "  `shift()` 메서드를 사용하여 이전 기간과의 차이를 계산하고, 변화율 분석에 활용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YRY7dagjwPN0"
   },
   "source": [
    "#**8. 데이터 시각화와 보고**\n",
    "데이터 시각화는 데이터를 직관적으로 이해하고, 숨겨진 패턴이나 인사이트를 도출하는 데 중요한 역할을 합니다. Pandas는 Matplotlib과의 원활한 연동을 통해 다양한 시각화 기능을 제공하며, 분석 결과를 효과적으로 보고하는 데 유용한 도구입니다. 이 장에서는 Pandas의 내장 시각화 기능, Matplotlib 연동, 시각화 커스터마이징 기법 및 보고서 작성 방법 등을 예제와 함께 살펴봅니다.\n",
    "\n",
    "##**8.1 Pandas 내장 시각화 기능**\n",
    "\n",
    "*   **Pandas Plot 메서드:**\n",
    "\n",
    "  Pandas DataFrame과 Series 객체에는 `plot()` 메서드가 내장되어 있어, 간단한 코드 한 줄로 다양한 종류의 그래프를 그릴 수 있습니다.\n",
    "\n",
    "*   **주요 그래프 종류:**\n",
    "\n",
    "  *   **선 그래프 (Line Plot):** 시계열 데이터나 연속적인 데이터의 추세를 시각화할 때 유용합니다.\n",
    "\n",
    "  *   **막대 그래프 (Bar Plot):** 범주형 데이터의 값들을 비교할 때 사용합니다.\n",
    "\n",
    "  *   **산점도 (Scatter Plot):** 전반적인 상승 또는 하강 추세를 보일 수 있습니다.\n",
    "\n",
    "  *   **히스토그램 (Histogram):** 데이터의 분포를 확인할 때 사용됩니다.\n",
    "\n",
    "  *   **상자 그림 (Box Plot):** 데이터의 분포, 중앙값, 사분위 범위 및 이상치를 한눈에 파악할 수 있습니다.\n",
    "\n",
    "*   **예제:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5wyNTHtzxLsD"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 예제 DataFrame 생성: 임의의 시계열 데이터\n",
    "dates = pd.date_range(start='2023-01-01', periods=50, freq='D')\n",
    "df = pd.DataFrame({\n",
    "    '매출': np.random.randint(100, 500, size=50),\n",
    "    '비용': np.random.randint(50, 300, size=50)\n",
    "}, index=dates)\n",
    "\n",
    "# 선 그래프: 시간에 따른 매출 변화\n",
    "df['매출'].plot(title=\"일별 매출 추이\", figsize=(8, 4))\n",
    "plt.xlabel(\"날짜\")\n",
    "plt.ylabel(\"매출\")\n",
    "plt.show()\n",
    "\n",
    "# 막대 그래프: 특정 날짜의 매출과 비용 비교 (예시로 첫 7일)\n",
    "df.iloc[:7].plot(kind='bar', title=\"일별 매출 및 비용 (첫 7일)\", figsize=(10, 5))\n",
    "plt.xlabel(\"날짜\")\n",
    "plt.ylabel(\"금액\")\n",
    "plt.show()\n",
    "\n",
    "# 히스토그램: 매출 분포\n",
    "df['매출'].plot(kind='hist', bins=10, title=\"매출 분포\", figsize=(8, 4))\n",
    "plt.xlabel(\"매출\")\n",
    "plt.show()\n",
    "\n",
    "# 상자 그림: 매출과 비용의 분포 및 이상치 확인\n",
    "df[['매출', '비용']].plot(kind='box', title=\"매출 및 비용 상자 그림\", figsize=(6, 4))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eGPXGp7UxN9z"
   },
   "source": [
    "##**8.2 Matplotlib 연동과 시각화 커스터마이징**\n",
    "\n",
    "*   **Matplotlib과의 연동:**\n",
    "\n",
    "  Pandas의 `plot()` 메서드는 기본적으로 Matplotlib을 사용하여 그래프를 그립니다. 따라서 Matplotlib의 다양한 옵션을 활용해 그래프의 스타일, 레이블, 축, 범례 등을 세밀하게 조정할 수 있습니다.\n",
    "\n",
    "*   **커스터마이징 기법:**\n",
    "\n",
    "  *   **제목 및 축 레이블 추가:** `plt.title()`, `plt.xlabel()`, `plt.ylabel()` 등을 사용합니다.\n",
    "\n",
    "  *   **범례 조정:** `plt.legend()`를 이용해 범례의 위치나 표시 방식을 변경합니다.\n",
    "\n",
    "  *   **그래프 크기 설정:** `figsize` 옵션을 통해 그래프의 가로, 세로 크기를 지정합니다.\n",
    "\n",
    "  *   **스타일 적용:** Matplotlib의 스타일 시트를 적용하여, 미리 정의된 테마로 그래프를 꾸밀 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1lOhDgOnxuWr"
   },
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rwoJsqQcxyaz"
   },
   "source": [
    "*   **예제:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lUD8GraFx1Rq"
   },
   "outputs": [],
   "source": [
    "# Matplotlib 스타일 적용 및 커스터마이징\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "ax = df['매출'].plot(title=\"커스터마이징된 일별 매출 추이\", figsize=(10, 5), color='blue', lw=2)\n",
    "ax.set_xlabel(\"날짜\", fontsize=12)\n",
    "ax.set_ylabel(\"매출\", fontsize=12)\n",
    "plt.legend(['매출'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_3JCOU1nyAp6"
   },
   "source": [
    "##**8.3 데이터 시각화를 활용한 보고서 작성**\n",
    "\n",
    "*   **보고서 작성의 중요성:**\n",
    "\n",
    "  시각화된 결과는 데이터 분석 보고서나 프레젠테이션에서 핵심 인사이트를 전달하는 데 중요한 역할을 합니다.\n",
    "\n",
    "  *   **명확한 제목과 설명:** 그래프마다 제목, 축 레이블, 범례, 주석 등을 추가하여 메시지를 명확하게 전달합니다.\n",
    "\n",
    "  *   **일관된 스타일:** 여러 그래프를 하나의 보고서에 포함할 경우, 색상, 폰트, 스타일 등을 일관되게 사용하여 전문적인 인상을 줍니다.\n",
    "\n",
    "  *   **해석과 결론:** 그래프를 단순히 나열하는 것을 넘어서, 각 시각화 결과에 대한 해석과 인사이트, 그리고 향후 조치나 결론을 명확하게 서술합니다.\n",
    "\n",
    "*   **보고서 구성 예시:**\n",
    "\n",
    "  *   **개요:** 분석 목적, 데이터 설명, 주요 지표 소개\n",
    "\n",
    "  *   **시각화 결과:** 각 그래프에 대한 상세 설명 및 해석\n",
    "\n",
    "  *   **결론:** 데이터에서 도출한 인사이트 및 제언\n",
    "\n",
    "  *   **추가 분석:** 필요 시 보조 그래프나 추가 통계 분석 결과 포함\n",
    "\n",
    "##**8.4 실습 예제 및 팁**\n",
    "\n",
    "*   **실습 예제:**\n",
    "\n",
    "  *   다양한 그래프 종류(선 그래프, 막대 그래프, 산점도, 히스토그램, 상자 그림 등)를 직접 그려보고, 각 그래프가 어떤 데이터 분석에 적합한지 토론합니다.\n",
    "\n",
    "  *   Matplotlib의 커스터마이징 옵션을 활용해, 같은 데이터를 서로 다른 스타일로 시각화해 비교합니다.\n",
    "\n",
    "  *   분석 결과를 바탕으로 보고서를 작성하고, 시각화 결과를 효과적으로 전달하는 방법을 실습합니다.\n",
    "\n",
    "*   **유의사항:**\n",
    "\n",
    "  *   데이터의 특성과 분석 목적에 맞는 그래프 종류를 선택해야 합니다.\n",
    "\n",
    "  *   그래프가 복잡해질 경우, 여러 개의 작은 서브플롯(subplot)으로 나누어 표현하는 것이 좋습니다.\n",
    "\n",
    "  *   시각화 도구와 보고서 작성 도구(예: Jupyter Notebook, PowerPoint, LaTeX 등)를 적절히 활용하여, 분석 결과를 명확하게 전달할 수 있도록 합니다.\n",
    "\n",
    "##**8.5 요약**\n",
    "\n",
    "*   **Pandas 내장 시각화:**\n",
    "\n",
    "  간단한 `plot()` 메서드를 통해 다양한 그래프를 손쉽게 생성할 수 있습니다.\n",
    "\n",
    "*   **Matplotlib 연동 및 커스터마이징:**\n",
    "\n",
    "  Matplotlib의 다양한 기능을 활용하여, 그래프의 디자인, 레이블, 범례 등 시각적 요소를 세밀하게 조정할 수 있습니다.\n",
    "  \n",
    "*   **보고서 작성:**\n",
    "\n",
    "  시각화 결과를 명확하게 해석하고, 일관된 스타일로 보고서를 작성함으로써, 데이터 분석의 인사이트를 효과적으로 전달할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vxa9xDxNzSB6"
   },
   "source": [
    "#**9. 실습 문제 및 응용 프로젝트**\n",
    "\n",
    "##**9.1 실습 문제의 목적 및 구성**\n",
    "\n",
    "*   **목적:**\n",
    "\n",
    "  *   Pandas의 기본 자료구조(Series, DataFrame), 데이터 입출력, 인덱싱 및 필터링, 전처리, 병합/결합 등 핵심 기능을 실제 데이터에 적용해보며 실력을 다집니다.\n",
    "\n",
    "  *   이론 수업에서 배운 내용을 직접 코딩해보고, 문제 해결 과정을 통해 분석 사고력을 기릅니다.\n",
    "\n",
    "*   **구성:**\n",
    "\n",
    "  실습 문제는 난이도에 따라 기본 문제, 중급 문제, 응용 문제로 나뉩니다.\n",
    "\n",
    "  *   **기본 문제:** Pandas의 자료구조 생성, 인덱싱 및 필터링, 기본 통계 함수 활용 등을 연습합니다.\n",
    "\n",
    "  *   **중급 문제:** 데이터 전처리(결측치 처리, 중복 제거, 데이터 타입 변환 등), 데이터 병합 및 결합, 그룹별 집계 및 피벗 테이블 작성 등 다양한 기능을 사용합니다.\n",
    "\n",
    "  *   **응용 문제 및 프로젝트:** 실제 데이터셋(예: 금융, 소셜 미디어, 시계열 데이터 등)을 활용해 분석, 시각화, 예측 모델링, 보고서 작성 등 종합적인 데이터 분석 과정을 수행합니다.\n",
    "\n",
    "##**9.2 실습 문제 예제**\n",
    "\n",
    "**예제 1: CSV 파일 데이터 분석 및 전처리**\n",
    "\n",
    "*   **문제 설명:**\n",
    "\n",
    "  주어진 CSV 파일에서 데이터를 읽어온 후, 결측치 확인 및 처리, 기본 통계량(평균, 중앙값, 분산) 계산, 그리고 특정 컬럼을 기준으로 데이터를 필터링합니다.\n",
    "\n",
    "*   **실습 목표:**\n",
    "\n",
    "  Pandas의 `read_csv()`, `isnull()`, `fillna()`, `describe()`, 불리언 인덱싱 등의 기능을 익힙니다.\n",
    "\n",
    "*   **예제 코드:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2IRNiGcj0oeD"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV 파일 읽기 (예: 'sales_data.csv')\n",
    "df = pd.read_csv('sales_data.csv', encoding='utf-8')\n",
    "\n",
    "# 데이터 미리보기 및 결측치 확인\n",
    "print(\"데이터 상위 5개:\")\n",
    "print(df.head())\n",
    "print(\"\\n각 열의 결측치 개수:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# 결측치 처리: '판매량' 열의 결측치는 0으로 대체\n",
    "df['판매량'] = df['판매량'].fillna(0)\n",
    "\n",
    "# 기본 통계량 출력\n",
    "print(\"\\n기초 통계량:\")\n",
    "print(df.describe())\n",
    "\n",
    "# '지역' 열이 '서울'인 데이터만 필터링하여 출력\n",
    "df_seoul = df[df['지역'] == '서울']\n",
    "print(\"\\n서울 지역 데이터:\")\n",
    "print(df_seoul)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YM_aphoJ0q8x"
   },
   "source": [
    "**예제 2: 그룹화 및 피벗 테이블 활용**\n",
    "\n",
    "*   **문제 설명:**\n",
    "\n",
    "  판매 데이터를 기반으로, 지역별 및 제품별 판매 총합과 평균을 계산하고 피벗 테이블로 재구성하여 비교합니다.\n",
    "\n",
    "*   **실습 목표:**\n",
    "\n",
    "  `groupby()`, `agg()`, `pivot_table()` 등의 함수를 사용하여 데이터를 요약하고 재구성하는 방법을 익힙니다.\n",
    "\n",
    "*   **예제 코드:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1740230584503,
     "user": {
      "displayName": "이유태",
      "userId": "01951466277766633919"
     },
     "user_tz": -540
    },
    "id": "m2Rv_k6G00xa",
    "outputId": "a4784c52-7ea9-4c4c-bcd9-425eec16dd62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "그룹별 요약:\n",
      "   지역 제품  판매량      매출\n",
      "0  대구  B  120  1300.0\n",
      "1  부산  A  280  1450.0\n",
      "2  서울  A  100  1000.0\n",
      "3  서울  B  380  2100.0\n",
      "\n",
      "피벗 테이블 (판매량):\n",
      "제품      A      B\n",
      "지역              \n",
      "대구    NaN  120.0\n",
      "부산  280.0    NaN\n",
      "서울  100.0  380.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 예제 데이터 생성\n",
    "data = {\n",
    "    '지역': ['서울', '부산', '서울', '대구', '부산', '서울'],\n",
    "    '제품': ['A', 'A', 'B', 'B', 'A', 'B'],\n",
    "    '판매량': [100, 150, 200, 120, 130, 180],\n",
    "    '매출': [1000, 1500, 2200, 1300, 1400, 2000]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 지역별, 제품별 판매 총합과 매출 평균 계산 (GroupBy 활용)\n",
    "group_summary = df.groupby(['지역', '제품']).agg({\n",
    "    '판매량': 'sum',\n",
    "    '매출': 'mean'\n",
    "}).reset_index()\n",
    "print(\"그룹별 요약:\")\n",
    "print(group_summary)\n",
    "\n",
    "# 피벗 테이블로 재구성: 지역을 행, 제품을 열로 하여 판매 총합 표시\n",
    "pivot = df.pivot_table(values='판매량', index='지역', columns='제품', aggfunc='sum')\n",
    "print(\"\\n피벗 테이블 (판매량):\")\n",
    "print(pivot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P9gmjH2107OR"
   },
   "source": [
    "##**9.3 응용 프로젝트 예제**\n",
    "\n",
    "**프로젝트 1: 금융 데이터 분석 및 예측 보고서**\n",
    "\n",
    "*   **목표:**\n",
    "\n",
    "  주식 시장 데이터를 활용하여 일별 주가, 거래량 등의 시계열 데이터를 분석하고, 이동 평균, 변동성 계산, 그리고 향후 추세를 예측하는 보고서를 작성합니다.\n",
    "\n",
    "*   **주요 내용:**\n",
    "\n",
    "  외부 API 또는 CSV 파일로부터 금융 데이터 수집\n",
    "  \n",
    "  시계열 데이터 인덱싱, 리샘플링, 이동 평균 및 변화율 계산\n",
    "  \n",
    "  데이터 시각화 (선 그래프, 상자 그림 등) 및 분석 결과 보고서 작성\n",
    "\n",
    "*   **예제 코드 (일부 발췌):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jw9P-ORD1Ni6"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 예제: 주식 데이터 CSV 파일 읽기 (예: 'stock_data.csv')\n",
    "df_stock = pd.read_csv('stock_data.csv', parse_dates=['날짜'], index_col='날짜')\n",
    "\n",
    "# 일별 종가의 20일 이동 평균 계산\n",
    "df_stock['20일_이동평균'] = df_stock['종가'].rolling(window=20).mean()\n",
    "\n",
    "# 주별 리샘플링: 주별 평균 종가 계산\n",
    "weekly_stock = df_stock['종가'].resample('W').mean()\n",
    "\n",
    "# 데이터 시각화: 일별 종가와 이동 평균\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(df_stock.index, df_stock['종가'], label='종가')\n",
    "plt.plot(df_stock.index, df_stock['20일_이동평균'], label='20일 이동평균', linewidth=2)\n",
    "plt.title(\"주식 일별 종가와 20일 이동 평균\")\n",
    "plt.xlabel(\"날짜\")\n",
    "plt.ylabel(\"가격\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 보고서 작성 시, 분석 결과에 대한 해석과 결론 포함 (텍스트 문서 작성)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hifD_3yS1XsS"
   },
   "source": [
    "**프로젝트 2: 소셜 미디어 데이터 분석**\n",
    "\n",
    "*   **목표:**\n",
    "\n",
    "  트위터나 인스타그램 등의 소셜 미디어 데이터를 활용하여, 특정 키워드에 대한 언급량, 감성 분석, 시간대별 활동 패턴 등을 분석하는 프로젝트입니다.\n",
    "\n",
    "*   **주요 내용:**\n",
    "\n",
    "  외부 API를 통해 데이터 수집 또는 CSV 파일로 제공된 데이터를 읽어오기\n",
    "  \n",
    "  데이터 전처리 (중복 제거, 결측치 처리, 텍스트 클렌징)\n",
    "  \n",
    "  키워드별 집계, 그룹별 통계, 시각화(막대 그래프, 워드 클라우드 등)\n",
    "  \n",
    "  분석 결과를 토대로 인사이트 도출 및 전략 제언\n",
    "\n",
    "*   **실습 포인트:**\n",
    "\n",
    "  문자열 처리 및 정규표현식을 통한 텍스트 전처리\n",
    "  \n",
    "  그룹화와 집계 함수를 활용한 데이터 요약\n",
    "  \n",
    "  Pandas와 Matplotlib, 추가 라이브러리(예: wordcloud)를 활용한 시각화\n",
    "\n",
    "*   **예제 코드:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CEXVurW92FBh"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "# CSV 파일에서 소셜 미디어 데이터 읽기\n",
    "# - '날짜' 열은 날짜형으로 파싱합니다.\n",
    "df = pd.read_csv('social_media.csv', encoding='utf-8', parse_dates=['날짜'])\n",
    "\n",
    "# 데이터 미리보기\n",
    "print(\"데이터 상위 5개:\")\n",
    "print(df.head())\n",
    "\n",
    "# 1. 특정 키워드(예: \"Python\") 언급 여부 확인\n",
    "#   - case=False를 사용해 대소문자 구분 없이 검색, 결측치는 False 처리\n",
    "df['키워드_포함'] = df['내용'].str.contains('Python', case=False, na=False)\n",
    "\n",
    "# 키워드 언급 데이터 확인 (상위 5개)\n",
    "print(\"\\n'Python' 키워드 언급 데이터 (상위 5개):\")\n",
    "print(df[df['키워드_포함']].head())\n",
    "\n",
    "# 2. 날짜별로 'Python' 키워드 언급 횟수 집계\n",
    "#    - '날짜' 열에서 날짜만 추출하여 그룹화 후 합계를 계산합니다.\n",
    "keyword_daily = df.groupby(df['날짜'].dt.date)['키워드_포함'].sum()\n",
    "print(\"\\n날짜별 'Python' 언급 횟수:\")\n",
    "print(keyword_daily)\n",
    "\n",
    "# 3. 날짜별 언급 횟수를 막대 그래프로 시각화\n",
    "plt.figure(figsize=(10, 5))\n",
    "keyword_daily.plot(kind='bar', color='skyblue')\n",
    "plt.title(\"날짜별 'Python' 언급 횟수\")\n",
    "plt.xlabel(\"날짜\")\n",
    "plt.ylabel(\"언급 횟수\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 4. 전체 글 내용의 단어 분포 확인 (간단한 빈도수 분석)\n",
    "all_text = ' '.join(df['내용'].dropna().tolist())\n",
    "words = all_text.split()\n",
    "word_counts = Counter(words)\n",
    "\n",
    "# 상위 10개 단어 출력\n",
    "print(\"\\n상위 10개 단어:\")\n",
    "for word, count in word_counts.most_common(10):\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "# (옵션) 5. Word Cloud 생성 - 단어 분포 시각화\n",
    "# WordCloud 패키지가 설치되어 있어야 합니다: pip install wordcloud\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# 한국어 폰트 경로를 지정해야 한글이 올바르게 표시됩니다. (예: 'malgun.ttf')\n",
    "wc = WordCloud(width=800, height=400, background_color='white', font_path='malgun.ttf').generate(all_text)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wc, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title(\"소셜 미디어 내용 워드 클라우드\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NwbVnMJ-2GGh"
   },
   "source": [
    "**코드 설명:**\n",
    "\n",
    "*   **데이터 읽기:**\n",
    "\n",
    "  `pd.read_csv()`를 통해 CSV 파일을 읽고, `parse_dates` 옵션으로 '날짜' 열을 datetime 형으로 변환합니다.\n",
    "\n",
    "*  **키워드 언급 확인:**\n",
    "\n",
    "  `str.contains()`를 사용해 '내용' 열에서 \"Python\" 키워드의 언급 여부를 불리언 값으로 저장합니다.\n",
    "\n",
    "*  **그룹별 집계 및 시각화:**\n",
    "\n",
    "  `groupby()`와 `dt.date`를 이용해 날짜별로 키워드 언급 횟수를 합산한 후, 막대 그래프로 시각화합니다.\n",
    "\n",
    "*  **단어 빈도수 분석:**\n",
    "\n",
    "  전체 텍스트를 하나의 문자열로 결합한 후, 단어별 빈도수를 계산하여 상위 10개 단어를 출력합니다.\n",
    "\n",
    "*  **워드 클라우드 생성 (선택 사항):**\n",
    "\n",
    "  WordCloud 라이브러리를 이용해 전체 텍스트의 단어 분포를 시각적으로 표현합니다. 한글 폰트 경로를 지정해 한글이 제대로 표시되도록 합니다.\n",
    "\n",
    "##**9.4 프로젝트 진행 시 유의사항**\n",
    "\n",
    "*   **문제 정의와 목표 설정:**\n",
    "\n",
    "  프로젝트 시작 전, 분석 목적과 문제 정의를 명확히 하고 요구사항을 정리합니다.\n",
    "\n",
    "*   **데이터 탐색:**\n",
    "\n",
    "  데이터를 불러온 후, 결측치, 이상치, 분포 등을 충분히 탐색하여 적절한 전처리 방법을 결정합니다.\n",
    "\n",
    "*   **코드 모듈화 및 재사용:**\n",
    "\n",
    "  함수와 모듈을 사용해 코드의 재사용성을 높이고, 각 단계별로 결과를 확인하며 진행합니다.\n",
    "\n",
    "*   **보고서 작성:**\n",
    "\n",
    "  시각화 자료와 함께 분석 결과, 인사이트, 결론을 포함한 보고서를 작성하여, 결과를 체계적으로 전달합니다.\n",
    "\n",
    "*   **재현성:**\n",
    "\n",
    "  코드와 데이터 처리 과정을 명확히 기록하여, 다른 사람도 동일한 결과를 재현할 수 있도록 합니다.\n",
    "\n",
    "##**9.5 요약**\n",
    "\n",
    "*   **실습 문제:**\n",
    "\n",
    "  Pandas의 기본 기능(데이터 읽기, 전처리, 인덱싱, 그룹화 등)을 연습하여 기초를 다집니다.\n",
    "\n",
    "*   **응용 프로젝트:**\n",
    "\n",
    "  실제 데이터셋을 활용한 분석 프로젝트를 통해, 데이터 수집부터 전처리, 분석, 시각화, 보고서 작성까지 전체 워크플로우를 경험합니다.\n",
    "\n",
    "*   **학습 효과:**\n",
    "\n",
    "  다양한 문제 해결 및 프로젝트 경험을 통해, Pandas를 이용한 데이터 분석 역량과 문제 해결 능력을 향상시킬 수 있습니다."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN9HkpqXOQ6HZpGN9DdsRBk",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
